{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hate Speech Detection",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "726428bac2554499bea783078bb6593e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0b9f83fe498f40f295d289003ab5ede2",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_550df98871f34af690e0b2ed26ec82a1",
              "IPY_MODEL_d7e477fe951543b590f2cf6eafaab77a"
            ]
          }
        },
        "0b9f83fe498f40f295d289003ab5ede2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "550df98871f34af690e0b2ed26ec82a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_cfc25ba9617647b4b9d5c75b066d54e6",
            "_dom_classes": [],
            "description": "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.2.2.json: ",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 23856,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 23856,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f05541c100ed484690cd8f1b58ad11a7"
          }
        },
        "d7e477fe951543b590f2cf6eafaab77a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b229c205c4de44a1885f836170339816",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 139k/? [00:00&lt;00:00, 3.05MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f3873f326dd646618515defee0898d93"
          }
        },
        "cfc25ba9617647b4b9d5c75b066d54e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f05541c100ed484690cd8f1b58ad11a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b229c205c4de44a1885f836170339816": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f3873f326dd646618515defee0898d93": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/victorknox/Hate-Speech-Detection-in-Hindi/blob/main/Hate_Speech_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XeHmXPtnwN8g"
      },
      "source": [
        "# Subjectivity Analysis\n",
        "- We use Sentiment lexicon resource for hindi called Hindi Sentiwordnet.\n",
        "- It has around 3000 prior-polarity subjective clues with POS tag, positive score, negative score and related terms(separated by comma)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "996HeBAnhq3k",
        "outputId": "6f72748a-9d73-48e3-d460-316aeaa73a35"
      },
      "source": [
        "SUBJCLUE = []                     # SUBJCLUE Data\n",
        "\n",
        "with open('SUBJCLUE.txt') as f:   # Formatting SUBJCLUE Data\n",
        "    for line in f:                # iterate over the lines of the file\n",
        "      x = line.split()            # split the line into a list of words\n",
        "      x[4] = x[4].split(',')      # split the list into a list of words\n",
        "      SUBJCLUE.append(x)          # append the list to the list of lists\n",
        "\n",
        "# After this, the data would be in this form:\n",
        "# ['POS tag', 'SYSNET ID(Hindi WN)', 'Positive score', 'Negative score', List of related words]\n",
        "\n",
        "# printing the first 5 rows\n",
        "for key in SUBJCLUE[:5]:\n",
        "  print(key[4])\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['अनौपचारिक']\n",
            "['मृत']\n",
            "['परवर्ती']\n",
            "['अच्छा', 'बढ़िया']\n",
            "['सौभाग्यशाली', 'खुशकिस्मत', 'खुशनसीब', 'तक़दीर_वाला', 'नसीब_वाला', 'भाग्यवान', 'भाग्यशाली', 'ख़ुशक़िस्मत', 'ख़ुशनसीब']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AADg4qY8qoyZ"
      },
      "source": [
        "## Reading the data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BmgETknXXHph"
      },
      "source": [
        "Note: The Dataset should be a csv file with Fields corresponding to Unique ID, Post, Labels Set "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gV-RT5LurrDr",
        "outputId": "423f29d0-a889-421a-b688-20a43b89a0ad"
      },
      "source": [
        "import csv                                  # importing csv module\n",
        "# csv file name\n",
        "\n",
        "filename = \"Dataset/valid.csv\"                      # change this file name to whatever you want\n",
        "  \n",
        "\n",
        "fields = []                                 # defining fields\n",
        "rows = []                                   # defining rows\n",
        "  \n",
        "with open(filename, 'r') as csvfile:        # opening csv file\n",
        "    # creating a csv reader object\n",
        "    csvreader = csv.reader(csvfile)\n",
        "      \n",
        "    # extracting field names through first row\n",
        "    fields = next(csvreader)\n",
        "  \n",
        "    # extracting each data row one by one\n",
        "    for row in csvreader:\n",
        "        rows.append(row)\n",
        "  \n",
        "    # get total number of rows\n",
        "    print(\"Total no. of rows: %d\"%(csvreader.line_num))\n",
        "  \n",
        "# printing the field names\n",
        "print('Field names are:' + ', '.join(field for field in fields))\n",
        "  \n",
        "#  printing first 5 rows\n",
        "# Appending a score for each row\n",
        "tot = 0\n",
        "for row in rows:\n",
        "    row.append(tot)\n",
        "    # print(row)\n",
        "# can be accessed using row[3]\n",
        "for row in rows[:5]:\n",
        "  print(row)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total no. of rows: 2259\n",
            "Field names are:Unique ID, Post, Labels Set\n",
            "['1', 'दृढ़ इच्छा शक्ति से परिपूर्ण प्रणबदा के लिए देशहित सर्वोच्च रहा।\\n\\nउनका निधन हम सब के लिए अपूरणीय क्षति है।\\nईश्वर दिवंगत आत्मा को अपने श्रीचरणों में स्थान दें। शोक संतप्त परिजनों के प्रति संवेदनाएं।\\nऊं शांति!!!', 'non-hostile', 0]\n",
            "['2', 'भारतीय जनता पार्टी rss वाले इतने गिरे हुए हैं जहां मैं रहती हूं वहां मेरी जासूसी  करा रहें है उसकी जासूस की पहचान मुझे अच्छी तरह है rss बीजेपी वाले की जासूस दिल्ली में कौन है उत्तर प्रदेश में कौन है हरियाणा राजस्थान में कौन है सबकी पहचान है मुझे मेरी नजर से बच नहीं सकते हो', 'defamation', 0]\n",
            "['3', 'कोरोना से निपटने की तैयारी / दिल्ली में 10 हजार बेड वाला दुनिया का सबसे बड़ा कोविड केयर सेंटर शुरू, राजनाथ-शाह ने डीआरडीओ के 1 हजार बेड वाले सेंटर का भी उद्घाटन किया\\nhttps://t.co/9rlQowAsFh #Delhi @ArvindKejriwal  @rajnathsingh @AmitShah @DRDO_India @WHO @crpfindia @ITBP_official', 'non-hostile', 0]\n",
            "['4', 'गवर्नर कॉन्फ्रेंस में PM मोदी बोले- शिक्षा नीति में सरकार का दखल कम होना चाहिए\\nhttps://t.co/ZvKgxk6dbd', 'non-hostile', 0]\n",
            "['5', 'यूपी: गाजीपुर में Toilet घोटाला, प्रधान व सचिव ने किया लाखों का गबन, मुर्दों के नाम पर बनवा डाले शौचालय\\n\\n#UP\\nhttps://t.co/hxM1uNNmX2', 'non-hostile', 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUHPthTzs42T"
      },
      "source": [
        "## Checking score\n",
        "\n",
        "Finding positive, negative and total scores for each sentence\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dEGBezazs61_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c0ce45a-d393-4df0-edc7-8b1840422748"
      },
      "source": [
        "count = 0                             # initialize count\n",
        "for key in SUBJCLUE:                  # for each word in SUBJCLUE\n",
        "  subjlist = key[4]                   # get the list of subjects         \n",
        "# subjlist = ['इच्छा', 'आत्मा', 'इतने']\n",
        "  for row in rows:                    # for each row in the csv file\n",
        "    if any([subjword in row[1] for subjword in subjlist]):  # if any of the words in the list are in the row's text\n",
        "      count += 1            # increment count\n",
        "      pos = float(key[2])   # get the pos value\n",
        "      neg = float(key[3])   # get the neg value\n",
        "      tot = pos - neg       # calculate the total\n",
        "      row[3] += tot         # add the total to the row's total\n",
        "\n",
        "# printing the number of occurences of sentiment words in dataset\n",
        "print(count)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10530\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imewqNVTN0cp"
      },
      "source": [
        "# Hate Lexicon Growing\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7c6WmGyF7oY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a085be0-5499-4361-eca5-c6bdd92ccb47"
      },
      "source": [
        "# Installing required modules\n",
        "!pip install stanza\n",
        "!pip install setuptools\n",
        "!pip install subzero\n",
        "!pip install inltk"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: stanza in /usr/local/lib/python3.7/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from stanza) (1.19.5)\n",
            "Requirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from stanza) (1.9.0+cu102)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from stanza) (3.17.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from stanza) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from stanza) (4.41.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.3.0->stanza) (3.7.4.3)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf->stanza) (1.15.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->stanza) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->stanza) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->stanza) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->stanza) (1.24.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (57.2.0)\n",
            "Requirement already satisfied: subzero in /usr/local/lib/python3.7/dist-packages (0.2.4)\n",
            "Requirement already satisfied: deepmerge in /usr/local/lib/python3.7/dist-packages (from subzero) (0.3.0)\n",
            "Requirement already satisfied: pyspin in /usr/local/lib/python3.7/dist-packages (from subzero) (1.1.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from subzero) (21.0)\n",
            "Requirement already satisfied: PyRTF3>=0.47.3 in /usr/local/lib/python3.7/dist-packages (from subzero) (0.47.5)\n",
            "Requirement already satisfied: PyInstaller in /usr/local/lib/python3.7/dist-packages (from subzero) (4.4)\n",
            "Requirement already satisfied: pipdeptree in /usr/local/lib/python3.7/dist-packages (from subzero) (2.0.0)\n",
            "Requirement already satisfied: PyParsing in /usr/local/lib/python3.7/dist-packages (from PyRTF3>=0.47.3->subzero) (2.4.7)\n",
            "Requirement already satisfied: pip>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from pipdeptree->subzero) (21.1.3)\n",
            "Requirement already satisfied: pyinstaller-hooks-contrib>=2020.6 in /usr/local/lib/python3.7/dist-packages (from PyInstaller->subzero) (2021.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from PyInstaller->subzero) (4.6.1)\n",
            "Requirement already satisfied: altgraph in /usr/local/lib/python3.7/dist-packages (from PyInstaller->subzero) (0.17)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from PyInstaller->subzero) (57.2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->PyInstaller->subzero) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->PyInstaller->subzero) (3.5.0)\n",
            "Requirement already satisfied: futures in /usr/local/lib/python3.7/dist-packages (from pyspin->subzero) (3.1.1)\n",
            "Requirement already satisfied: inltk in /usr/local/lib/python3.7/dist-packages (0.9)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.7/dist-packages (from inltk) (2.7.3)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from inltk) (1.19.5)\n",
            "Requirement already satisfied: aiohttp>=3.5.4 in /usr/local/lib/python3.7/dist-packages (from inltk) (3.7.4.post0)\n",
            "Requirement already satisfied: fastprogress>=0.1.19 in /usr/local/lib/python3.7/dist-packages (from inltk) (1.0.0)\n",
            "Requirement already satisfied: spacy>=2.0.18 in /usr/local/lib/python3.7/dist-packages (from inltk) (2.2.4)\n",
            "Requirement already satisfied: bottleneck in /usr/local/lib/python3.7/dist-packages (from inltk) (1.3.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from inltk) (1.1.5)\n",
            "Requirement already satisfied: typing in /usr/local/lib/python3.7/dist-packages (from inltk) (3.7.4.3)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from inltk) (0.1.96)\n",
            "Requirement already satisfied: async-timeout>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from inltk) (3.0.1)\n",
            "Requirement already satisfied: nvidia-ml-py3 in /usr/local/lib/python3.7/dist-packages (from inltk) (7.352.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from inltk) (2.23.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from inltk) (1.4.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from inltk) (21.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from inltk) (4.6.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from inltk) (7.1.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from inltk) (3.2.2)\n",
            "Requirement already satisfied: fastai==1.0.57 in /usr/local/lib/python3.7/dist-packages (from inltk) (1.0.57)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from inltk) (3.13)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from fastai==1.0.57->inltk) (1.9.0+cu102)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from fastai==1.0.57->inltk) (0.10.0+cu102)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp>=3.5.4->inltk) (5.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp>=3.5.4->inltk) (3.7.4.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp>=3.5.4->inltk) (21.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp>=3.5.4->inltk) (1.6.3)\n",
            "Requirement already satisfied: chardet<5.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp>=3.5.4->inltk) (3.0.4)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18->inltk) (3.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18->inltk) (1.0.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18->inltk) (57.2.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18->inltk) (2.0.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18->inltk) (0.8.2)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18->inltk) (0.4.1)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18->inltk) (1.0.5)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18->inltk) (7.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18->inltk) (4.41.1)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18->inltk) (1.0.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.0.18->inltk) (1.1.3)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.0.18->inltk) (4.6.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.0.18->inltk) (3.5.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->inltk) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->inltk) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->inltk) (1.24.3)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->inltk) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->inltk) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->inltk) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->inltk) (0.10.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib->inltk) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->inltk) (2018.9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 553,
          "referenced_widgets": [
            "726428bac2554499bea783078bb6593e",
            "0b9f83fe498f40f295d289003ab5ede2",
            "550df98871f34af690e0b2ed26ec82a1",
            "d7e477fe951543b590f2cf6eafaab77a",
            "cfc25ba9617647b4b9d5c75b066d54e6",
            "f05541c100ed484690cd8f1b58ad11a7",
            "b229c205c4de44a1885f836170339816",
            "f3873f326dd646618515defee0898d93"
          ]
        },
        "id": "8HQa7z-8CQ32",
        "outputId": "5c20696d-8d85-40a5-e32e-ce9433745b70"
      },
      "source": [
        "SYNSET = []                                                     # SYNSET is a list of lists\n",
        "with open('Synset.txt', encoding= 'unicode_escape') as f:       # opening synset.txt file\n",
        "    for line in f:                                              # iterating through SYNSET        \n",
        "        x = line.split()                                        # splitting lines\n",
        "        x[3] = x[3].split(':')                                  # [3] is the synonyms\n",
        "        SYNSET.append(x)                                        # append to SYNSET\n",
        "\n",
        "import stanza                                                   # stanza is a library for natural language processing\n",
        "stanza.download('hi', processors='tokenize,pos,lemma')          # download the stanza library for Hindi NLP\n",
        "\n",
        "import csv                                                      # csv is a library for reading and writing csv files\n",
        "dataset = \"\"                                                    # dataset is a string\n",
        "\n",
        "for row in rows:                                                # iterating through rows\n",
        "    dataset+=row[1]                                             # appending to dataset\n",
        "\n",
        "verbs_content = []                                              # verbs_content is a list of lists\n",
        "nlp = stanza.Pipeline('hi',processors='tokenize,pos,lemma')     # nlp is a pipeline for processing text\n",
        "# pos = open('hindi_pos.txt','w')                                 # opening hindi_pos.txt in write mode\n",
        "doc = nlp(dataset)                                              # doc is a document object\n",
        "for sentence in doc.sentences:                                  # iterating through sentences\n",
        "     for word in sentence.words:                                # iterating through words\n",
        "         if word.upos == 'VERB':                                # if word is a verb\n",
        "             verbs_content.append(word.text)                    # append to verbs_content\n",
        "\n",
        "strongly_negative_words = []                                    # strongly_negative_words is a list\n",
        "weakly_negative_words = []                                      # weakly_negative_words is a list\n",
        "for line in SUBJCLUE:                                           # iterating through SUBJCLUE\n",
        "    totalscore = float(line[2]) - float(line[3])                # calculating total score\n",
        "    if(totalscore < -0.25):                                     # if total score is less than -0.35\n",
        "      for word in line[4]:                                      # iterating through words in line[4]\n",
        "        strongly_negative_words.append(word)                    # append to strongly_negative_words\n",
        "    elif totalscore < 0:                                        # if total score is less than 0\n",
        "      for word in line[4]:                                      # iterating through words in line[4]\n",
        "        weakly_negative_words.append(word)                      # append to weakly_negative_words\n",
        "        \n",
        "def Getsynset(word):                                            # Getsynset is a function\n",
        "    syn = []                                                    # syn is a list\n",
        "    flag=0                                                      # flag is a variable\n",
        "    syn.append(word)                                            # appending word to syn\n",
        "    for line in SYNSET:                                         # iterating through SYNSET\n",
        "        if(line[1]==\"03\"):                                      # if line[1] is equal to 03\n",
        "            for verb in line[3]:                                # iterating through verbs in line[3]\n",
        "                if(word == verb):                               # if word is equal to verb\n",
        "                    flag = 1                                    # flag is set to 1\n",
        "                    break                                       # break\n",
        "            if(flag):                                           # if flag is set to 1\n",
        "                syn = line[3]                                   # syn is set to line[3]\n",
        "                break                                           # break\n",
        "    return syn                                                  # return syn\n",
        "\n",
        "s = {}                                                          # s is a dictionary\n",
        "hlex = []                                                       # hlex is a list\n",
        "\n",
        "slist = [\"लड़ना\" , \"मारना\" , \"लूटना\" , \"पीटना\" , \"कूटना\" , \"भेदभाव\" ,\"फोड़ना\", \"तोड़ना\", \"उखाड़ना\" ]    # slist is a list of verbs\n",
        "for word in slist:                                                                              # iterating through slist\n",
        "  hlex.append(word)                                                                             # appending to hlex\n",
        "for word in slist:                                                                              # iterating through slist\n",
        "    s = Getsynset(word)                                                                         # s is set to Getsynset\n",
        "    for verb1 in s:                                                                             # iterating through s\n",
        "        if verb1 in verbs_content:                                                              # if verb1 is in verbs_content\n",
        "            hlex.append(verb1)                                                                  # appending to hlex\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "726428bac2554499bea783078bb6593e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading https://raw.githubusercontent.com/stanfordnlp…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "2021-07-29 18:03:09 INFO: Downloading these customized packages for language: hi (Hindi)...\n",
            "=======================\n",
            "| Processor | Package |\n",
            "-----------------------\n",
            "| tokenize  | hdtb    |\n",
            "| pos       | hdtb    |\n",
            "| lemma     | hdtb    |\n",
            "| pretrain  | hdtb    |\n",
            "=======================\n",
            "\n",
            "2021-07-29 18:03:09 INFO: File exists: /root/stanza_resources/hi/tokenize/hdtb.pt.\n",
            "2021-07-29 18:03:09 INFO: File exists: /root/stanza_resources/hi/pos/hdtb.pt.\n",
            "2021-07-29 18:03:09 INFO: File exists: /root/stanza_resources/hi/lemma/hdtb.pt.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2021-07-29 18:03:10 INFO: File exists: /root/stanza_resources/hi/pretrain/hdtb.pt.\n",
            "2021-07-29 18:03:10 INFO: Finished downloading models and saved to /root/stanza_resources.\n",
            "2021-07-29 18:03:10 INFO: Loading these models for language: hi (Hindi):\n",
            "=======================\n",
            "| Processor | Package |\n",
            "-----------------------\n",
            "| tokenize  | hdtb    |\n",
            "| pos       | hdtb    |\n",
            "| lemma     | hdtb    |\n",
            "=======================\n",
            "\n",
            "2021-07-29 18:03:10 INFO: Use device: cpu\n",
            "2021-07-29 18:03:10 INFO: Loading: tokenize\n",
            "2021-07-29 18:03:10 INFO: Loading: pos\n",
            "2021-07-29 18:03:10 INFO: Loading: lemma\n",
            "2021-07-29 18:03:10 INFO: Done loading processors!\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8xt1a-9EB76",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6c4b2ab-88be-46b1-f252-fa8b30ed4807"
      },
      "source": [
        "# open themenouns.txt in read\n",
        "themed_nouns = open('themenouns.txt','r')\n",
        "themenouns = []                                 # list of theme nouns\n",
        "for line in themed_nouns:                       # read the file line by line\n",
        "    themenouns.append(line.rstrip('\\n'))        # append the theme nouns to the list\n",
        "print(themenouns)                               # printing the theme nouns list"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['बीजेपी ', 'मोदी ', 'माओवादियों ', 'इस्लाम ', 'धमकी ', 'सुरक्षा ', 'धर्म ', 'साले ', 'कुत्ते ', 'कुतिया', 'कुते ', 'कुत्ती', 'कुत्तो', 'कमीना', 'कमीनी', 'साला', 'साली', 'हरामी', 'हरामखोर', 'बहनचोद', 'मादरचोद', 'चूतिया', 'चूत', 'चुत', 'टट्टी', 'नाजायज', 'झांट', 'सुअर', 'बेटीचोद', 'गांड', 'भोसड़ी', 'रन्डी', 'रांड', 'भड़वे', 'लौड़ा', 'लोडे', 'लवड़ा', 'चोर ', 'औलाद ', 'चीन ', 'औकात ', 'चुनौती', 'कश्मीर ', 'ज़ुल्म ', 'मरकज ', 'भारत', 'आतंकवाद', 'इस्लामिक', 'तालिबानी', 'हिन्दू ', 'अर्नब ', 'गद्दारों ', 'कलंकित ', 'तोड़फोड़ ', 'शिवसेना ', 'मंदिर ', 'राम ', 'हिन्दुओं ', 'शूद्र ', 'मुसलमान ', 'विपक्षी ', 'आग ', 'कॉंग्रेस ', 'आतंकवादी ', 'डायन ', 'पलटू ', 'फेंकूँ ', 'पाकिस्तान ', 'जिंदाबाद ', 'आतंकी ', 'आतंकी ', 'आतंकियों ', 'हिंदुस्तान ', 'हिन्दुओं', 'नेता', 'गुलाम ', 'पीओके ', 'आरएसएस ', 'भैंसियो ', 'चमचों ', 'पिल्ला ', 'गधे ', 'तबाह ', 'मुसलमान ', 'मुसलमानों ', 'मौलवी ', 'धर्म ']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PUjlJvTANlud"
      },
      "source": [
        "# Hate speech Detection Algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wk_UjwC5IrJI",
        "outputId": "89ba138d-76e7-4930-ed2a-2acde821cbe5"
      },
      "source": [
        "print(strongly_negative_words)  # printing the strongly negative words\n",
        "print(weakly_negative_words)    # printing the weakly negative words\n",
        "print(hlex)                     # printing the hlex words\n",
        "print(themenouns)               # printing the themenouns "
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['मृत', 'दुर्भाग्यशाली', 'अभागा', 'बदनसीब', 'भाग्यहीन', 'मनहूस', 'बदकिस्मत', 'मंदभाग्य', 'बदक़िस्मत', 'दईमारा', 'कमबख्त', 'कमबख़्त', 'अधन्य', 'अभागी', 'आवासहीन', 'आश्रयहीन', 'गृहहीन', 'गृहविहीन', 'बेघर', 'बेघरबार', 'अगतिक', 'अगेह', 'अनिकेत', 'बदबूदार', 'दुर्गंधपूर्ण', 'दुर्गंधयुक्त', 'दुर्गंधित', 'ढीला', 'अश्लिष्ट', 'असंयुक्त', 'असंयोजित', 'असंबद्ध', 'अलग', 'अजुड़ा', 'अजोड़', 'पृथक्', 'जुदा', 'पृथक', 'अपृक्त', 'पराधीन', 'गुलाम', 'परतंत्र', 'अन्याधीन', 'अपरवश', 'परवश', 'अवश', 'अबस', 'ढीला', 'जड़', 'अचैतन्य', 'जड़त्वयुक्त', 'स्थूल', 'अजैव', 'भौतिक', 'अचेतन', 'चेतनारहित', 'अजीव', 'अनात्म', 'आत्मारहित', 'अफल', 'अफलित', 'फलहीन', 'फलरहित', 'फलविहीन', 'निस्संतान', 'निःसंतान', 'बेऔलाद', 'संतानहीन', 'संतानरहित', 'अऊत', 'अनपत्य', 'भली-भाँति', 'भली_भाँति', 'भरपूर', 'भलीभाँति', 'भली-भांति', 'भली_भांति', 'भलीभांति', 'पंखहीन', 'पक्षरहित', 'अपक्ष', 'अपच्छी', 'अपत्र', 'अतकनीकी', 'ग़ैरतकनीकी', 'गैरतकनीकी', 'तकनीकहीन', 'प्राविधिहीन', 'दुर्गुणी', 'अगुणी', 'अपगुणी', 'ऐबी', 'खोटा', 'विपरीत', 'प्रतिकूल', 'खिलाफ', 'ख़िलाफ़', 'विरुद्ध', 'प्रतीप', 'कुस्वभावी', 'कुबुद्धि', 'दुश्शील', 'बदमिज़ाज', 'बदमिजाज', 'निकम्मा', 'निठल्ला', 'अकर्मण्य', 'निखट्टू', 'अनेरा', 'बेकार', 'फालतू', 'गायताल', 'अकर्मा', 'नालायक', 'ना-लायक', 'अनलायक', 'बेकदर', 'बेक़दर', 'बेक़द्र', 'बेकद्र', 'कठोरहृदय', 'कठोर_हृदय', 'पत्थरदिल', 'संगदिल', 'पाषाण_हृदय', 'हानिकारक', 'क्षतिकारी', 'हानिकर', 'नुक़सानदेह', 'नुकसानदेह', 'हानिप्रद', 'अनर्थकारी', 'क्षतिकर', 'अपमानजनक', 'गूदेदार', 'अप्रसन्नतापूर्वक', 'नाराज़गीपूर्वक', 'नाख़ुशी_से', 'नाराजगीपूर्वक', 'नाखुशी_से', 'पास_में', 'नज़दीक', 'नजदीक', 'निकट_में', 'क़रीब_में', 'समीप', 'निकट', 'पास', 'क़रीब', 'करीब', 'सन्निकट', 'खपड़ा', 'खपरा', 'खपड़ैल', 'खपरैल', 'खप्पर', 'खप्पड़', 'टाइल', 'टॉइल', 'संघर्ष', 'जंग', 'लड़ाई', 'द्वंद्व', 'द्वन्द्व', 'उन्मुक्त', 'आज़ाद', 'आजाद', 'खुला', 'बंधनमुक्त', 'मुक्त', 'अजाद', 'अनिबद्ध', 'मुंच', 'बन्धनमुक्त', 'अबद्ध', 'वीत', 'खीज', 'झुँझलाहट', 'कुढ़न', 'भँड़ास', 'खुंदक', 'खीस', 'अनख', 'भय', 'खौफ', 'ख़ौफ़', 'डर', 'त्रास', 'भीति', 'संत्रास', 'अपभय', 'दहशत', 'खीजना', 'झुँझलाना', 'खिजलाना', 'खिजना', 'कुढ़ना', 'खलना', 'बुरा_लगना', 'अखरना', 'विलाप_करना', 'कलपना', 'बिलखना', 'सोचना', 'दुखी_होना', 'सोंचना', 'अनमनाना', 'उदास_होना', 'अनमनाना', 'चिंताजनक', 'गंभीर', 'चिंतनीय', 'नाजुक', 'शोचनीय', 'सोचनीय', 'नाज़ुक', 'लँगड़ाना', 'लँगड़ाहट', 'लँगड़ापन', 'भचक', 'रुंडित', 'रुण्डित', 'अकारण', 'बेमतलब', 'निष्कारण', 'कारणहीनतः', 'अनिमित्त', 'बिगाड़ना', 'खराब_करना', 'उड़ना', 'गायब_होना', 'छू-मंतर_होना', 'उड़न-छू_होना', 'छूमंतर_होना', 'उड़नछू_होना', 'रौंद', 'रौंदाई', 'हँसी-मज़ाक़', 'हँसी-मजाक', 'हँसी_मज़ाक़', 'हँसी_मजाक', 'खिलवाड़', 'खेलवाड़', 'दिल्लगी', 'ठिठोली', 'ठट्ठा', 'हास्य-परिहास', 'हास-परिहास', 'विनोद', 'कौतुक', 'हँसी', 'परिहास', 'चुहल', 'प्रहसन', 'मज़ाक', 'मजाक', 'हास्य', 'विनोदोक्ति', 'अभिहास', 'धमा-चौकड़ी', 'धमाचौकड़ी', 'उछल-कूद', 'उछलकूद', 'कूद-फाँद', 'कूदफाँद', 'फुसफुसाहट', 'फुसफुस', 'फुस-फुस', 'खुसुफुसाहट', 'खुसुरफुसुर', 'खुसफुसाहट', 'खुसरफुसर', 'खुसर-फुसर', 'खुसुर-फुसुर', 'खुसखुस', 'खुस-खुस', 'खुसपुस', 'खुस_-फुस', 'तेजाबी', 'तेज़ाबी', 'तलछटी', 'अवसादी', 'तलोंछी', 'तलौछी', 'नकलची', 'नक़लची', 'अनुकारी', 'अनुहारक', 'अनुहारी', 'नीचा', 'निम्न', 'अतुंग', 'निभृत', 'अनुच्च', 'अनुन्नत्त', 'अनुन्नत', 'अनूर्ध्व', 'अरक्तक', 'अनीमिक', 'अल्परक्तक', 'अस्थिहीन', 'निराशाजनक', 'जनित', 'जन्य', 'बेहिसाब', 'बेहिसाबी', 'अनलेखा', 'बेपरवाह', 'बेपरवा', 'बिन्दास', 'बेफिक्र', 'बेफ़िक़्र', 'अलगरजी', 'अल्हड़', 'अचिंत', 'अचिन्त', 'उपेक्षक', 'निस्पृह', 'निःस्फृह', 'निर्लोभ', 'लोभहीन', 'लालचहीन', 'अलोभी', 'अस्पृह', 'अतृष्ण', 'लालसारहित', 'तृष्णारहित', 'अपरिवर्तित', 'अनबदला', 'सेवानिवृत्त', 'रिटायर', 'अवकाश_प्राप्त', 'रिटायर्ड', 'तेजहीन', 'निस्तेज', 'बुझा_हुआ', 'आभाहीन', 'कांतिहीन', 'ओजहीन', 'प्रभाहीन', 'फीका', 'बेरौनक', 'अप्रभ', 'प्रभारहित', 'धूलिधूसर', 'धूलि_धूसर', 'धूलिधूसरित', 'धूलि_धूसरित', 'धूसर', 'धूसरा', 'धूलधूसरित', 'तैलीय', 'तेलीय', 'स्निग्ध', 'तेलहा', 'कीचड़दार', 'पंकिल', 'कीचदार', 'कार्दम', 'चिलहला', 'अस्पृश्य', 'अछूत', 'छुतिहा', 'अपरस', 'भ्रमित', 'भ्रांत', 'भ्रान्त', 'क़रीबी', 'नज़दीकी', 'नजदीकी', 'निकटवर्ती', 'समीपी', 'निकटस्थ', 'सन्निकट', 'समीपवर्ती', 'समीपस्थ', 'अपदांतर', 'अपदान्तर', 'शत्रुतापूर्ण', 'दुश्मनाना', 'वैरपूर्ण', 'बैरपूर्ण', 'गरम', 'गर्म', 'उष्ण', 'ताबदार', 'शीतल', 'ठंडा', 'अनुष्ण', 'अतप्त', 'ठण्डा', 'ठंढा', 'ठण्ढा', 'मटमैला', 'ढबैला', 'आग्नेय', 'अदह', 'अदाह्य', 'बेआराम', 'चिरकालीन', 'चिरकालिक', 'दीर्घकालीन', 'दीर्घकालिक', 'दीर्घ-कालीन', 'दीर्घ-कालिक', 'चिर-कालीन', 'चिर-कालिक', 'बिखरा', 'छितराया', 'फैला', 'विकीर्ण', 'बिखरा_हुआ', 'अफ़शाँ', 'अफ़शान', 'अफशान', 'अफशाँ', 'अजेय', 'अजय', 'अजित', 'अपराजेय', 'दुर्जेय', 'अजीत', 'चेतनाहीनता', 'चेतनाशून्यता', 'अचेतनता', 'अचेतना', 'असंज्ञता', 'नाशक', 'नाशी', 'विनाशी', 'विनाशक', 'विनायक', 'विध्वंसक', 'अपध्वंसी', 'अपह', 'अपाय', 'संतोषी', 'संतोषशील', 'छिटपुट', 'छुटपुट', 'छिट-पुट', 'छुट-पुट', 'थोड़ा-बहुत', 'हल्का-फुल्का', 'अवश्य', 'वश_से_परे', 'अराजक', 'अनाथ', 'नाथहीन', 'अनीश', 'अनीस', 'निश्शंक', 'अनाशंकित', 'आशंकाहीन', 'बेखटक', 'बेफ़िक्र', 'संशयहीन', 'अविवाद्य', 'वादातीत', 'असुविधाजनक', 'असुविधापूर्ण', 'नरभक्षी', 'आदमखोर', 'आदमख़ोर', 'मनुष्यभक्षी', 'नौसिखिया', 'कच्चा', 'नव_प्रशिक्षित', 'नौसिखुआ', 'नया', 'नौसिख', 'असिद्ध', 'अनभ्यस्त', 'अपक्व', 'भ्रष्टाचारी', 'मिटनेवाला', 'अशरीरी', 'अशारीरिक', 'रूहानी', 'जड़ित', 'जड़ाऊ', 'जड़ावदार', 'अभिनिविष्ट', 'ख़राब', 'खराब', 'बिगड़ा', 'विकृत', 'विकारग्रस्त', 'अपभ्रंश', 'अपभ्रंशित', 'अबतर', 'विद्रूप', 'अघोषित', 'पराजित', 'परास्त', 'पस्त', 'अपध्वस्त', 'अवज्ञात', 'अभिभवनीय', 'अभिभूत', 'अभिमृष्ट', 'अभिशक्त', 'अनत', 'अनझुका', 'अनमित', 'मौलिक', 'स्वकृत', 'स्वरचित', 'मूल', 'अननुकृत', 'फलाना', 'फलाँ', 'अमुक', 'फलां', 'फला', 'फ़लाँ', 'अमका-धमका', 'फ़लाना', 'अमका', 'म्लान', 'कुम्हलाया', 'मुरझाया', 'रेतीला', 'बालूदार', 'बलुआ', 'सैकत', 'बालुई', 'बलुई', 'बलसुम', 'सिकतिल', 'अखंडनीय', 'अखण्डनीय', 'अभंजनीय', 'अखंड्य', 'अखण्ड्य', 'अत्यावश्यक', 'अति_आवश्यक', 'अपरिहार्य', 'गौण', 'स्वाधीनतः', 'स्वतंत्र_रूप_से', 'अनिर्धारित', 'अनिश्चित', 'वैकल्पिक', 'अप्रतिपन्न', 'अप्रतीयमान', 'सहज', 'आसान', 'सरल', 'सुगम', 'अविकट', 'सहल', 'असावधान', 'लापरवाह', 'अचेत', 'असजग', 'अनचित', 'अनचित्ता', 'ग़फ़लती', 'गफलती', 'अनवहित', 'अनवधान', 'अनाचित', 'गाफिल', 'ग़ाफ़िल', 'अप्रत्यक्ष', 'परोक्ष', 'असीमांकित', 'अक्षुण्ण', 'अक्षुण', 'अविभाजित', 'अखंड', 'अखण्ड', 'अभग्न', 'अविभक्त', 'अखंडित', 'अखण्डित', 'अटूट', 'अभिन्न', 'अखूट', 'अजस्र', 'अनंतरित', 'अनन्तरित', 'अनंतर्हित', 'अनन्तर्हित', 'अनवच्छिन्न', 'अभंग', 'अभङ्ग', 'अभंगी', 'अभङ्गी', 'अभंजन', 'अभञ्जन', 'अभेदनीय', 'अपृथक्', 'अपृथक', 'अभिन्न', 'अभेद', 'अभेव', 'अभेय', 'नीरसता', 'रुचिहीनता', 'अरोचकता', 'ख़ुश्की', 'खुश्की', 'अनरस', 'फीकापन', 'रसहीनता', 'अनर्जित', 'ऋणात्मक', 'ऋण', 'मृत', 'कठिनाई', 'कठिनता', 'मुश्किल', 'बखेड़ा', 'दुरुहता', 'किल्लत', 'क़िल्लत', 'थकाऊ', 'शैक्षिक', 'तालीमी', 'इल्मी', 'सशंकित', 'शंकित', 'सशंक', 'आशंकित', 'आशंकित', 'आशंकापूर्ण', 'फ़िक्रमंद', 'आतंकित', 'त्रस्त', 'भयाक्रांत', 'संत्रस्त', 'भयातुर', 'भयाकुल', 'रोमांचित', 'ग्लानिरहित', 'अकलंक', 'अकलंकित', 'अकलंकी', 'असहमत', 'असम्मत', 'वसाहीन', 'वसामुक्त', 'अमेदस्क', 'अनगढ़', 'अनगढ़ा', 'अनघढ़', 'अनंत', 'असमाप्य', 'अंतहीन', 'अनन्त', 'अन्तहीन', 'अनवसान', 'अयोग्य', 'अनुपयुक्त', 'नाक़ाबिल', 'नाकाबिल', 'अनर्ह', 'नालायक', 'ना-लायक', 'अनलायक', 'अपारग', 'अप्रभु', 'अनम्य', 'अनमनीय', 'कठोर', 'दृढ़', 'अपारिवारिक', 'अपरिवारीय', 'अक्षमाशील', 'अक्षमावान', 'परित्यक्त', 'त्यक्त', 'अपरिगृहीत', 'अपवर्जित', 'अपविद्ध', 'अपास्त', 'अभिनियुक्त', 'विकलांग', 'अपाहिज', 'अंगहीन', 'अपंग', 'अपाहज', 'अपराधी', 'अपराधक', 'अपराध_कर्ता', 'क़सूरवार', 'कसूरवार', 'क़ुसूरवार', 'कुसूरवार', 'गुनहगार', 'दोषी', 'मुजरिम', 'गुनाहगार', 'दंडनीय', 'सहन', 'बर्दाश्त', 'बरदाश्त', 'दुख', 'दुःख', 'तक़लीफ़', 'तकलीफ', 'कष्ट', 'क्लेश', 'परेशानी', 'कोफ़्त', 'कोफ्त', 'अघ', 'अनिर्वृत्ति', 'व्यथित', 'दुःखी', 'दुखी', 'आर्त', 'रंजीदा', 'अनुतपत', 'दिलगीर', 'आनंदपूर्ण', 'आनंदमय', 'उल्लासपूर्ण', 'सानंद', 'अनबूझ', 'अविचारित', 'अचिंतित', 'अचिन्तित', 'अचीता', 'अनचीत', 'अनचीता', 'अनबूझ', 'अनूह', 'औरस', 'ढीला', 'लापता', 'खोया_हुआ', 'गुमशुदा', 'खोया', 'गुम', 'अजूबा', 'प्रियभाषी', 'प्रियंवद', 'प्रियवादी', 'वयस्क', 'बालिग', 'सयाना', 'स्याना', 'अपोगंड', 'बालिग़', 'अप्रधान', 'अप्रमुख', 'आनुषंगिक', 'गौण', 'अविवाहित', 'अनब्याहा', 'कुँआरा', 'कुँवारा', 'क्वाँरा', 'कुंवार', 'कँवारा', 'क्वारा', 'बिनब्याहा', 'अनूढ़', 'अपरिणीत', 'जनाना', 'औरताना', 'स्त्री-सम्बन्धी', 'बचकाना', 'बेमौसम', 'अनार्तव', 'निरर्थक', 'अर्थहीन', 'व्यर्थ', 'फजूल', 'फ़ज़ूल', 'वाहियात', 'बेमतलब_का', 'सारहीन', 'अर्थशून्य', 'अनर्थक', 'अनाह', 'फिजूल', 'फ़िज़ूल', 'वृथा', 'अपार्थ', 'निरामिष', 'अनामिष', 'मांसरहित', 'शस्त्रहीन', 'निहत्था', 'निरस्त्र', 'निश्शस्त्र', 'अबान', 'निरभिमानी', 'अनभिमानी', 'अभिमानरहित', 'गर्वहीन', 'दर्पहीन', 'अदंभी', 'अदर्पी', 'निरहंकारी', 'अहंकारहीन', 'दंभहीन', 'निरहंकर', 'निरहंकृत', 'सीधा', 'अनमद', 'अहंकाररहित', 'गर्वरहित', 'मदशून्य', 'अपरुष', 'अभिमानशून्य', 'अनैतिक', 'नैतिकताहीन', 'अनीतिपूर्ण', 'अनुचित', 'ग़लत', 'गलत', 'नीतिविरुद्ध', 'कम', 'थोड़ा', 'जरा', 'ज़रा', 'अल्प', 'न्यून', 'तनि', 'तनिक', 'कुछ', 'लेश', 'आंशिक', 'अनति', 'अप्रचुर', 'अबहु', 'ऊन', 'तोष', 'अभूयिष्ट', 'अभूरि', 'अमर', 'मृत्यु_विजेता', 'कालजयी', 'कालजीत', 'कालातीत', 'मृत्युंजय', 'अमर्त्य', 'चिरंजीव', 'चिरंजीवी', 'चिरजीवी', 'चिरंजी', 'अंतर्राष्ट्रीय', 'अंतरराष्ट्रीय', 'अंताराष्ट्रीय', 'बहुदेशीय', 'बहुराष्ट्रीय', 'अप्राकृतिक', 'अप्राकृत', 'दिखावटी', 'बनावटी', 'ऊपरी', 'बनौवा', 'स्वाभाविक', 'स्वाभावगत', 'परजीवी', 'लज्जित', 'शर्मिंदा', 'शर्मिन्दा', 'शरमिंदा', 'शरमिन्दा', 'शर्मसार', 'शरमसार', 'शरमाया_हुआ', 'शरमाया', 'अधिकारी', 'अफ़सर', 'अफसर', 'हाकिम', 'निरस्त', 'रद्द', 'निरसित', 'मंसूख', 'मूसलाधार', 'मूसलधार', 'निर्विरोध', 'हरा', 'ठीक-ठाक', 'ठीक_से', 'ठीक-ठाक_से', 'ठीकठाक', 'दुविधाजनक', 'दुबिधाजनक', 'अनिश्चयात्मक', 'भ्रामक', 'संशयात्मक', 'अनुकृत', 'अमौलिक', 'अवैतनिक', 'निर्वेतन', 'अप्रिय', 'अप्रीतिकर', 'नागवार', 'कठिन', 'दुर्गम', 'अगम्य', 'अगम', 'दुरूह', 'दुर्गम्य', 'बीहड़', 'अगत', 'बंक', 'आगम', 'अनाथ', 'यतीम', 'लावारिस', 'बेकस', 'पितृहीन', 'पितृविहीन', 'पिताहीन', 'पितविहीन', 'तातहीन', 'अपितृ', 'अपितृक', 'मातृहीन', 'माताहीन', 'मातृविहीन', 'माताविहीन', 'अमातृक', 'उपद्रवग्रस्त', 'अशांतिपूर्ण', 'अनुशयी', 'पश्चात्तापी', 'अनुशायी', 'अनुशोचत', 'इंद्रियातीत', 'अतींद्रिय', 'अगोचर', 'गोतीत', 'अतीन्द्रिय', 'अप्रत्यक्ष', 'परोक्ष', 'अभौतिक', 'अभ्रमित', 'भ्रमरहित', 'अभ्रांत', 'अभ्रान्त', 'अभरम', 'अप्रमाद', 'निर्भेद्य', 'अभेद्य', 'अप्रवेश्य', 'अगम्य', 'अगत', 'अगम', 'आगम', 'मनोविज्ञानिक', 'मनोवैज्ञानिक', 'मनोविज्ञानी', 'अरोचक', 'नीरस', 'रुचिहीन', 'फीका', 'बेमजा', 'बेमज़ा', 'ख़ुश्क', 'खुश्क', 'अरस', 'असार', 'अप्रासंगिक', 'अप्रासाङ्गिक', 'प्रसंगहीन', 'प्रसङ्गहीन', 'अनुपयुक्त', 'अप्रसंगिक', 'अप्रसङ्गिक', 'अप्रासांगिक', 'अप्रासांङ्गिक', 'ऋणात्मक', 'ऋण', 'अध्यारोपित', 'मिथ्यारोपित', 'असंभव', 'असम्भव', 'अनहोनी', 'असंभावित', 'नामुमकिन', 'असंभावी', 'असंभाव्य', 'अशक्य', 'अघटित', 'अघट', 'अनहोता', 'नामर्द', 'नपुंसक', 'पौरुषहीन', 'पुरषत्वहीन', 'वीर्यहीन', 'अपौरुष', 'अपुरुष', 'शंड', 'विवश', 'बाध्य', 'बेबस', 'मजबूर', 'लाचार', 'जिच', 'जिच्च', 'ज़िच', 'ज़िच्च', 'अवश', 'अबस', 'अनुपस्थित', 'ग़ैरहाज़िर', 'गैरहाजिर', 'ग़ैरमौज़ूद', 'गैरमौजूद', 'अविद्यमान', 'अप्रस्तुत', 'अप्राप्त', 'वंचित', 'महरूम', 'फल', 'फर', 'प्रसून', 'ताल', 'अनुचित', 'असंगत', 'विसंगत', 'गलत', 'ग़लत', 'नामुनासिब', 'अनधिकारी', 'स्वत्वहीन', 'दंडित', 'दण्डित', 'सज़ायाफ़ता', 'सजायाफ्ता', 'अप्रशिक्षित', 'अनसिखा', 'निरुद्विग्न', 'अविकल', 'अव्याकुल', 'प्रशांत', 'शांत', 'निभृत', 'अनाकुल', 'अव्यग्र', 'शान्त', 'प्रशान्त', 'मोपेड', 'निरपवाद', 'अनुपचारित', 'अचिकित्सित', 'अनुपलब्ध', 'अप्राप्य', 'अलभ्य', 'अनधिगम्य', 'अनमिलता', 'अप्राप्त', 'अनियमित', 'नियमरहित', 'बेकायदा', 'बेक़ायदा', 'जलना', 'अग्राह्य', 'अग्रह्य', 'अग्रहणीय', 'असंबंधित', 'असंबद्ध', 'संबंधरहित', 'अटपट', 'अटपटा', 'अनन्वित', 'अप्रसंग', 'असम्बन्धित', 'असम्बद्ध', 'सम्बन्धरहित', 'अबद्ध', 'दुर्व्यवहार', 'दुराचार', 'कुव्यवहार', 'बदसलूकी', 'अनाचार', 'दुराचरण', 'अनाचरण', 'कदाचार', 'कुचाल', 'अपचाल', 'दुष्टाचरण', 'अपकरण', 'अपचार', 'पलायनवाद', 'हवाई_चप्पल', 'स्लीपर', 'अनादरणीय', 'निरादरणीय', 'असम्माननीय', 'अमाननीय', 'अपूजनीय', 'अपूज्य', 'अमान्य', 'खेल', 'तमाशा', 'खेल_प्रदर्शन', 'झाड़ा_फिरना', 'पाखाना_करना', 'पाख़ाना_करना', 'टट्टी_करना', 'दिशा_मैदान_करना', 'करना', 'परिवर्तित_रूप', 'साधनहीन', 'साधनविहीन', 'अज्ञात', 'अनजान', 'अनजाना', 'अविदित', 'अनवगत', 'अपरिचित', 'अपरिगत', 'अनधिगत', 'अनभिज्ञ', 'अज्ञ', 'गुमनाम', 'अजन', 'अजान', 'अजाना', 'बेख़बर', 'बेखबर', 'नावाक़िफ़', 'अनागत', 'अप्रपन्न', 'इच्छाहीनता', 'अनाकांक्षा', 'अनिच्छा', 'अस्पृहा', 'अकामता', 'अनभिलाषिता', 'अनीहा', 'निस्पृहता', 'सौहार्द्र', 'लापरवाही', 'असावधानी', 'सावधानीहीनता', 'अचेतपना', 'चित्तविक्षेप', 'बेपरवाही', 'अलगरजी', 'ग़फ़लत', 'गफलत', 'अनवधान', 'अनवधानता', 'अनाचिती', 'अचिंता', 'अचिन्ता', 'निश्चिंतता', 'निश्चिन्तता', 'निश्चिंतई', 'बेफ़िक्री', 'बेफ़िक़्री', 'बेफिक्री', 'बेफिकरी', 'दिखाना', 'दिखलाना', 'कुरूपता', 'बदसूरती', 'अपाटव', 'दिवालिया', 'दीवालिया', 'दामासाह', 'धर्मनिरपेक्ष', 'अस्वीकृत', 'नामंजूर', 'नामंज़ूर', 'सहमतिहीन', 'सहमति_अप्राप्त', 'और', 'अन्य', 'अवैज्ञानिक', 'विज्ञान_विरूद्ध', 'असांप्रदायिक', 'संवेदनशील', 'कोमलमनस्क', 'संक्रमित', 'अनावासिक', 'प्रतिगामी', 'पश्चगामी', 'पश्चगंता', 'डाँवाडोल', 'डाँवाँडोल', 'घुमक्कड़', 'घुमंतू', 'घुमन्तू', 'पर्यटनप्रिय', 'यायावर', 'जहाँगर्द', 'घूमनेवाला', 'रमता', 'भ्रमणशील', 'भ्रमणीय', 'अतिचारी', 'अध्वगामी', 'ग़श्ती', 'गश्ती', 'घुमना', 'अंधा', 'अन्धा', 'दृष्टिहीन', 'नेत्रहीन', 'अंध', 'अन्ध', 'अँधला', 'अक्षहीन', 'अचक्षु', 'अनयन', 'चक्षुहीन', 'सूरदास', 'वर्णांध', 'वर्णांधता_से_पीड़ित', 'कठिन', 'दुरुह', 'बारीक़', 'बारीक', 'सूक्ष्म', 'अबोधगम्य', 'मुँह-देखा', 'मुंडा', 'केशहीन', 'अलिपिबद्ध', 'अलिखित', 'जीवाणुनाशन', 'विसंक्रमण', 'अनाड़ी', 'अप्रवीण', 'अकुशल', 'अदक्ष', 'अनिपुण', 'अधकचरा', 'अनाप्त', 'अनारी', 'अनैपुण', 'अपटु', 'अपाटव', 'अपात्र', 'ढीला', 'खुरदुरा', 'खुरदरा', 'खुरखुरा', 'कर्कश', 'रूखा', 'रुक्ष', 'रूख', 'छूट', 'चूक', 'ग़फ़लत', 'गफलत', 'असामाजिक', 'गैसीय', 'अनेक', 'कई', 'विविध', 'नाना', 'एकाधिक', 'कतिपय', 'अनेकानेक', 'तमाम', 'अनेग', 'सड़ा', 'स्वरित', 'अबाध्य', 'कुपोषित', 'कुटिल', 'अंटीबाज़', 'अंटीबाज', 'अनार्जव', 'अड़ियल', 'अड़बल', 'अड़ुआ', 'निष्फल', 'असफल', 'विफल', 'व्यर्थ', 'निरर्थक', 'नाकाम', 'अकृतार्थ', 'अपरिणामी', 'परिणामरहित', 'फलरहित', 'अफल', 'अफलित', 'उन्नीस', 'उनीस', 'उन्नीस', 'उनीस', 'अनियत', 'अनिश्चित', 'अनियमित', 'अनिर्दिष्ट', 'अध्रुव', 'सूत्र', 'स्रोत', 'असंदिग्ध', 'संदेहहीन', 'असन्दिग्ध', 'सन्देहहीन', 'तरीक़े_से', 'तरीके_से', 'तरतीब_से', 'क़रीने_से', 'करीने_से', 'व्यवस्थापूर्वक', 'व्यवस्थिततः', 'क़रीनावार', 'करीनावार', 'ठिंगना', 'छोटा', 'बौना', 'नाटा', 'ठिगना', 'वामन', 'वन्य', 'जंगली', 'बनैला', 'आरण्य', 'साउज', 'उलटा-पुलटा', 'उलटा_पुलटा', 'उलटा-पलटा', 'उल्टा-पल्टा', 'उल्टा-पुल्टा', 'उल्टा_पुल्टा', 'कड़ुआ', 'कड़ुवा', 'कड़वा', 'कटु', 'कड़ू', 'सूत्र', 'स्रोत', 'संयमित', 'टूटना', 'अविचारणीय', 'अचिंतनीय', 'अविचार्य', 'असह्य', 'असह', 'असहनीय', 'नागवार', 'ना-गवार', 'अनसहत', 'अप्रसह्य', 'दुरुपयोग', 'महा_युद्ध', 'व्यापक_युद्ध', 'महाभारत', 'महायुद्ध', 'अछूता', 'अश्रुपूर्ण', 'डबडबा', 'डबकौंहाँ', 'डभकौंहाँ', 'अश्रुयुक्त', 'साश्रु', 'अश्रुपूरित', 'अकर्मक', 'अनुपयोगी', 'अनावश्यक', 'उपयोगहीन', 'निरर्थक', 'बेकार', 'व्यर्थ', 'फालतू', 'लंद-फंद', 'अकाज', 'अकारज', 'अकारथ', 'अकारत', 'अनर्थक', 'बेफ़ायदा', 'बेफायदा', 'बेकाम', 'अखंडनीय', 'अखण्डनीय', 'अभंजनीय', 'अखंड्य', 'अखण्ड्य', 'दुष्कर्मी', 'अकृत्यकारी', 'अपकर्मी', 'खल', 'अकर्मी', 'अदृश्य', 'अदृष्टिगोचर', 'लोचनातीत', 'अदृश्यमान', 'विलीन', 'अडीठ', 'अदर्श', 'अनदेखा', 'अदिष्ट', 'अनडीठ', 'अपेख', 'अंतर्हित', 'अन्तर्हित', 'तिरोहित', 'अनिच्छित', 'अचाहा', 'अनचाहा', 'अनपेक्षित', 'अवांछित', 'अनचाहत', 'अनचीत', 'अनचीता', 'अनिष्ट', 'अनभिलषित', 'अनीठ', 'अनीप्सित', 'अजाति', 'अजात', 'जाति_निर्वासित', 'जातिच्युत', 'जाति_बहिष्कृत', 'अजाती', 'अंधाधुंध', 'बेतहाशा', 'मधुमेही', 'मधुमेह_रोगी', 'धब्बेदार', 'दाग़दार', 'दागदार', 'कुपथ्य', 'अपथ्य', 'स्वाधीनतः', 'स्वतंत्र_रूप_से', 'उड़ानहीन', 'उड़नहीन', 'खूनी', 'ख़ूनी']\n",
            "['अच्छा', 'बढ़िया', 'कठिनाई_से', 'जैसे_तैसे', 'मुश्किल_से', 'कठिनतः', 'सड़ा', 'हत', 'वधित', 'मक़तूल', 'दोस्ताना', 'मित्रवत', 'मित्रतापूर्ण', 'मित्रोचित', 'मैत्रीपूर्ण', 'मृतजात', 'असफल', 'नाकामयाब', 'विफल', 'नाकाम', 'निष्फल', 'फौलादी', 'इस्पाती', 'फ़ौलादी', 'इसपाती', 'अभी_भी', 'पूर्व_काल_में', 'पहले', 'कठिनाई_से', 'जैसे_तैसे', 'मुश्किल_से', 'कठिनतः', 'टकराना', 'भिड़ाना', 'खोलना', 'आच्छादित', 'ढँका', 'आवृत्त', 'अपिबद्ध', 'अपिनद्ध', 'अपिहित', 'आच्छन्न', 'उलटना', 'पलटना', 'मासिक', 'अविलंब', 'अविलम्ब', 'छुड़ाना', 'छोड़ाना', 'कृतज्ञ', 'एहसानमंद', 'अहसानमंद', 'आभारी', 'शुक्रगुज़ार', 'शुक्रगुजार', 'उपकृत', 'अनुगृहीत', 'छुड़ाना', 'छोड़ाना', 'उजाड़ना', 'उजाड़_देना', 'नष्ट_करना', 'ख़ाक_करना', 'नाश_करना', 'मिटाना', 'चौपट_करना', 'प्रति', 'कापी', 'कॉपी', 'भयभीत', 'डरा_हुआ', 'डरा', 'कातर', 'आतंकित', 'ख़ौफ़ज़द', 'भयग्रस्त', 'भयान्वित', 'भीत', 'अपत्रस्त', 'दहशतज़दा', 'दहशतजदा', 'सकपकाना', 'चकपकाना', 'भौंचक्का_होना', 'भौचक्का_होना', 'चौंकना', 'पछताना', 'पश्चाताप_करना', 'अछताना-पछताना', 'अफ़सोस_करना', 'अफसोस_करना', 'अपसोसना', 'जलना', 'ईर्ष्या_करना', 'द्वेष_करना', 'डाह_करना', 'कुढ़ना', 'टहलना', 'घूमना', 'विचरना', 'सैर_करना', 'भुजा', 'हाथ', 'बाज़ू', 'हस्त', 'बाँह', 'कर', 'बाहु', 'बाजू', 'झुलसन', 'झुरसन', 'झौंस', 'टूटना', 'उतरना', 'दूभर', 'दुर्भर', 'भीषण', 'भयानक', 'अत्यधिक', 'घनघोर', 'भारी', 'फूँकना', 'फूंकना', 'सँवरना', 'सजना', 'बनना-ठनना', 'शृंगार_करना', 'सजना-धजना', 'जलाना', 'प्रज्वलित_करना', 'जानना', 'समझना', 'बूझना', 'घायल', 'जख्मी', 'ज़ख़्मी', 'आहत', 'क्षत', 'अपचायित', 'चोटिल', 'अभिप्रहत', 'सिसकना', 'सिसकी_भरना', 'सिसकी_लेना', 'सुबकना', 'सुबकी_लेना', 'फूँकना', 'फूंकना', 'जँभाई', 'उबासी', 'जम्हाई', 'जमहाई', 'जम्भाई', 'थोपना', 'ठेलना', 'मत्थे_मढ़ना', 'ठेल_देना', 'डालना', 'लादना', 'भीड़', 'जमघट', 'हुजूम', 'जमाव', 'जमावड़ा', 'भीड़-भाड़', 'भीड़भाड़', 'चहल-पहल', 'चहलपहल', 'मेला', 'मजमा', 'ठट', 'ठठ', 'अंबोह', 'चेतावनी', 'तम्बीह', 'अनुपयोगी', 'अनावश्यक', 'उपयोगहीन', 'निरर्थक', 'बेकार', 'व्यर्थ', 'फालतू', 'लंद-फंद', 'अकाज', 'अकारज', 'अकारथ', 'अकारत', 'अनर्थक', 'बेफ़ायदा', 'बेफायदा', 'बेकाम', 'नारकीय', 'नारकिक', 'नरकीय', 'ईमानदार', 'छलहीन', 'निष्कपट', 'निःकपट', 'रिजु', 'ऋजु', 'दयानतदार', 'सच्चा', 'अपैशुन', 'मोमी', 'मोमिया', 'आसीन', 'विराजमान', 'उपविष्ट', 'अध्यासीन', 'अभिनिविष्ट', 'तरंगित', 'उत्तरंग', 'उर्मिल', 'तरंगी', 'लहरित', 'तरंगायित', 'सक्षम', 'क्षमतावान', 'सामर्थ्यवान', 'क्षमताशाली', 'सामर्थी', 'अपरिवर्तनीय', 'अपरिवर्तनशील', 'अजूना', 'रेडियोधर्मी', 'रेडियोएक्टिव', 'अपारदर्शक', 'अपारदर्शी', 'क्रुद्ध', 'क्रोधित', 'कुपित', 'भामी', 'क्षुब्ध', 'अनखौहा', 'खुला', 'अनावृत', 'अनाच्छादित', 'अनढँका', 'आवरणहीन', 'आवरणरहित', 'अनावेष्टित', 'अपरछन', 'अपरिच्छन्न', 'अप्रच्छन्न', 'विस्फोटक', 'विस्फोटक_पदार्थ', 'कथनीय', 'कथ्य', 'वाच्य', 'अभिभाष्य', 'असघन', 'अघन', 'विरल', 'असंघनित', 'अवचेतन', 'उदारतापूर्वक', 'आत्मतुष्ट', 'आत्मसंतुष्ट', 'आत्मतृप्त', 'नियमी', 'नेमी', 'नियम_पालक', 'आत्मानुशासी', 'विवादित', 'विवादास्पद', 'वादग्रस्त', 'विवादग्रस्त', 'निजाई', 'खरा', 'चोखा', 'सच्चा', 'झबरीला', 'भेंगा', 'तिरपटा', 'कैंचा', 'ऐंचताना', 'सर्गपताली', 'धेरा', 'त्रि-आयामी', 'त्रि-आयामिक', 'त्रिआयामी', 'त्रिआयामिक', 'त्रिविम', 'त्रिविमीय', 'छिछला', 'उथला', 'सतही', 'विद्रोही', 'बाग़ी', 'बागी', 'बलवाई', 'गद्दार', 'ग़द्दार', 'खंडनीय', 'भंजनीय', 'धराशायी', 'भूलुठिंत', 'भू-लुठिंत', 'भूलुण्ठित', 'भू-लुण्ठित', 'अप्रतिष्ठित', 'अप्रतिष्ठ', 'प्रतिष्ठारहित', 'प्रबंधक', 'व्यवस्थापक', 'मैनेजर', 'प्रबंधकर्ता', 'नियामक', 'मुंतजिम', 'प्रबंध_कर्ता', 'प्रबंध-कर्ता', 'प्रबंधकर्त्ता', 'प्रबंध_कर्त्ता', 'प्रबंध-कर्त्ता', 'प्रबन्ध_कर्ता', 'प्रबन्धकर्ता', 'प्रबन्ध_कर्त्ता', 'प्रबन्ध-कर्ता', 'प्रबन्ध-कर्त्ता', 'प्रबन्धकर्त्ता', 'कुरूप', 'बदशक्ल', 'बदसूरत', 'भद्दा', 'असुंदर', 'भदेस', 'भदेसिल', 'भोंडा', 'भौंड़ा', 'अनगढ़', 'अनभिरूप', 'अनरूप', 'अपाटव', 'अबंधुर', 'अबन्धुर', 'अप्रभावित', 'अप्रभान्वित', 'असामयिक', 'अकालिक', 'रोमांचकारी', 'रोमांचक', 'लोमहर्षक', 'अपेक्षणीय', 'अपेक्ष्य', 'सुपरिचित', 'दुबला', 'पतला', 'क्षीण', 'कृशकाय', 'कृश', 'दुबरा', 'अकृत', 'अनकिया', 'विदेशी', 'परदेशी', 'बिदेसी', 'परदेसी', 'विस्मरणीय', 'औपचारिक', 'उपरोक्त', 'उपर्युक्त', 'उल्लिखित', 'उपरिलिखित', 'पूर्वोक्त', 'ऊपर_लिखा', 'रसदार', 'रसपूर्ण', 'रसीला', 'सरस', 'रसवंत', 'रसवान', 'रसाल', 'रसहीन', 'नीरस', 'बेरस', 'त्रिपद', 'त्रिपाद', 'अनुपालन', 'लंबा', 'लंबोतरा', 'बड़ा', 'अपमान', 'अनादर', 'बेइज्जती', 'बे-इज्जती', 'निरादर', 'तिरस्कार', 'हेठी', 'तौहीन', 'तोहीनी', 'जिल्लत', 'फ़ज़ीअत', 'फ़ज़ीहत', 'फजीअत', 'फजीहत', 'अवमान', 'अवमानना', 'अवमानन', 'मानध्वंस', 'मानभंग', 'पराभव', 'बेकदरी', 'भद्द', 'अधिक्षेप', 'अपकर्ष', 'अपचार', 'अपध्वंस', 'बेक़द्री', 'अपहेला', 'अपूजा', 'अप्रतिष्ठा', 'अभिभव', 'आधार', 'अवलंब', 'अवलम्ब', 'आश्रय', 'सहारा', 'पाया', 'अधिकरण', 'जड़', 'अधार', 'अधारी', 'अधिष्ठान', 'कोमलता', 'कोमलताई', 'मुलायमियत', 'मृदुलता', 'नरमीयत', 'नरमी', 'नरमाई', 'नर्मी', 'विचारहीन', 'सतही', 'हल्का', 'स्वर्ण_निर्मित', 'कांचन', 'हैम', 'मध्यम', 'अत्याधुनिक', 'अति-आधुनिक', 'बहुत', 'अधिक', 'ज्यादा', 'ज़्यादा', 'ख़ूब', 'खूब', 'अतिशय', 'अति', 'अगाध', 'अतीव', 'काफ़ी', 'काफी', 'अंबोह', 'अनल्प', 'अनून', 'अन्यून', 'अबेश', 'स्वाभाविक', 'स्वाभावगत', 'शैवाल', 'सेवार', 'तोयशूका', 'तोयवृक्ष', 'जलपृष्ठजा', 'अंबुचामर', 'अम्बुचामर', 'निराशावादी', 'अव्यवस्थित', 'व्यवस्थाहीन', 'अनवस्थ', 'सामान्य', 'आम', 'साधारण', 'कामचलाऊ', 'मामूली', 'अविशिष्ट', 'अविशेष', 'अदिव्य', 'पत्तीदार', 'पर्णी', 'पल्लवित', 'अल्बानियाई', 'अल्बानियावासी', 'अल्बानिया-वासी', 'हृदय-विदारक', 'हृदय_विदारक', 'मार्मिक', 'हृदय_भंजक', 'मर्मभेदी', 'मर्मघाती', 'दिखावटी', 'बनावटी', 'ऊपरी', 'बनौवा', 'दिखावटी', 'बनावटी', 'ऊपरी', 'बनौवा', 'समांतर', 'समानांतर', 'समान्तर', 'समानान्तर', 'अतीत', 'गत', 'भूत', 'व्यतीत', 'बीता', 'गया', 'गुज़रा', 'पिछला', 'विगत', 'पुराना', 'अपेत', 'वर्तमान', 'अजन्मा', 'अजात', 'अनुत्पन्न', 'अनुद्भूत', 'अप्रादुर्भूत', 'अज', 'स्वयंभू', 'स्वयंभु', 'अजन', 'अजन्म', 'अनन्यभव', 'अनागत', 'शांतिपूर्ण', 'शन्तिपूर्ण', 'शांतिमय', 'शान्तिमय', 'अकशेरुकी_जंतु', 'अकशेरुकी_जन्तु', 'अकशेरुकी', 'अकशेरुकी_प्राणी', 'बिल्ली', 'बिलारी', 'बिलाई', 'बिलैया', 'मार्जारी', 'मार्जारीय', 'विड़ाल', 'विराल', 'लार्वा', 'बछेड़ी', 'धनी', 'रोमंथक', 'रोमंथक_प्राणी', 'रोमन्थक', 'रोमन्थक_पशु', 'रोमंथक', 'रोमन्थक', 'लामा', 'विरोधात्मक', 'अधिकारपूर्ण', 'साधिकार', 'बाइख़्तियार', 'बाइख्तियार', 'कंटकारिका', 'अंगुरशफा', 'साग_अंगुर', 'बेलाडोना', 'अवश्यंभावी', 'अटल', 'तय', 'अटलनीय', 'अनिवार्य', 'अबाध्य', 'काज', 'ताश', 'तास', 'कार्ड', 'पत्ता', 'गंजीफा', 'गंजीफ़ा', 'जाँच', 'अप्रधान', 'अप्रमुख', 'आनुषंगिक', 'गौण', 'निजी', 'अपना', 'स्वकीय', 'स्वायत्त', 'आत्म', 'होनहार', 'अवनतिशील', 'पतनशील', 'पतनोन्मुख', 'डायरी', 'दैनंदिनी', 'दैनन्दिनी', 'दैनिकी', 'रोजनामचा', 'रोज़नामचा', 'डाइनमो', 'डाइनेमो', 'ओरी', 'ओलती', 'कढ़ाई', 'कशीदा', 'गुलकारी', 'फुलकारी', 'कढ़ाव', 'असत्यापित', 'अप्रमाणित', 'अनुपपन्न', 'अपरीक्षित', 'फाउंटेन_पेन', 'स्रोतलेखनी', 'हिलाना', 'डुलाना', 'विलोड़न', 'व्यायामशाला', 'व्यायाम_शाला', 'प्रदूषित', 'छँटनी', 'छँटाई', 'हेरोइन', 'लेस', 'लैस', 'मग', 'कलगी', 'कँगूरा', 'कंगूरा', 'जेल', 'जेलख़ाना', 'कारागार', 'बंदी_गृह', 'क़ैदख़ाना', 'कैदखाना', 'कारावास', 'हवालात', 'अस्त्र', 'गुप्ती', 'टरबाइन', 'टरबाईन', 'टरबाइन_मशीन', 'टरबाईन_मशीन', 'निर्धन', 'ग़रीब', 'गरीब', 'दरिद्र', 'दीन', 'धनहीन', 'छुद्र', 'क्षुद्र', 'कंगाल', 'असमृद्ध', 'असंपन्न', 'धनधान्यहीन', 'विपन्न', 'दीनहीन', 'बेचारा', 'मुफ़लिस', 'मुफलिस', 'आजिज़', 'आजिज', 'अकिंचन', 'अनाढ्य', 'असम्पन्न', 'रंक', 'तंगहाल', 'अनिभ्य', 'तंगदस्त', 'विधन', 'बपुरा', 'बापुरा', 'मिसकिन', 'मिस्किन', 'मिसकीन', 'बेकस', 'धनी', 'व्यक्तित्व', 'मानसिक_अवस्था', 'मनोदशा', 'मानसिकता', 'मनःस्थिति', 'मूड', 'मनो_अवस्था', 'मनोवस्था', 'रुखाई', 'रूखापन', 'रुक्षता', 'रुक्षत्व', 'रुखावट', 'रुखाहट', 'अनरस', 'प्रभाव', 'असर', 'छाप', 'रङ्ग', 'तासीर', 'अनुभाव', 'विकार', 'विकृति', 'बिगाड़', 'अपभ्रंश', 'कसर', 'आत्मघाती', 'डुप्लीकेट', 'समरूप', 'धमा-चौकड़ी', 'धमाचौकड़ी', 'उछल-कूद', 'उछलकूद', 'कूद-फाँद', 'कूदफाँद', 'असंतोषजनक', 'असंतोषप्रद', 'गुप्ततः', 'गुपचुप_रूप_से', 'चोरी_छिपे', 'निश्चित', 'निर्धारित', 'नियत', 'ठीक', 'निर्दिष्ट', 'कुडौल', 'कुगठित', 'बेडौल', 'बेढंगा', 'बेढब', 'अनगढ़', 'अनघढ़', 'अपरूप', 'अहस्ताक्षरित', 'बग़ैरदस्तख़ती', 'सेवा-शुश्रूषा', 'शुश्रूषा', 'तीमारदारी', 'बिजैला', 'बीजदार', 'निर्वीज', 'बीजरहित', 'राजद्रोह', 'तारायुक्त', 'तारांकित', 'तारों_भरा', 'तारकिंत', 'टेढ़ा', 'तिरछा', 'तिर्यक', 'आड़ा', 'घुमावदार', 'चक्करदार', 'अटित', 'मस्सा', 'मसा', 'मशक', 'माष', 'अधीन', 'आधीन', 'असहाय', 'निस्सहाय', 'बेसहारा', 'निराश्रित', 'निराश्रय', 'अनाश्रित', 'आश्रयहीन', 'अपाश्रय', 'निरवलंब', 'अवलंबहीन', 'अवलंबनहीन', 'निरवलम्ब', 'अवलम्बहीन', 'अवलम्बनहीन', 'बेचारा', 'बपुरा', 'बापुरा', 'अनवस्थित', 'अनाथ', 'निरवलम्ब', 'अनाश्रित', 'निःसहाय', 'बेकस', 'नज़र', 'नजर', 'कुदृष्टि', 'बुरी_नज़र', 'डीठ', 'चुप्पा', 'घुन्ना', 'अनालाप', 'बुनाई', 'बिनाई', 'बुनावट', 'ध्रुव_तारा', 'ध्रुव', 'सुकुमार', 'कोमल', 'नाजुक', 'नाज़ुक', 'कोमलांग', 'मृदुल', 'फूलपान', 'रुआँसा', 'रोवासा', 'रोआँसा', 'रोनी', 'निर्णीत', 'निर्णित', 'निपटा_हुआ', 'तय', 'तयशुदा', 'आच्छादित', 'ढँका', 'आवृत्त', 'अपिबद्ध', 'अपिनद्ध', 'अपिहित', 'आच्छन्न', 'जरायुज', 'गर्भज', 'पिंडज', 'पिण्डज', 'गरम', 'गर्म', 'उष्ण', 'ताबदार', 'शीतल', 'ठंडा', 'अनुष्ण', 'अतप्त', 'ठण्डा', 'ठंढा', 'ठण्ढा', 'ऊपर', 'कम', 'थोड़ा', 'जरा', 'ज़रा', 'अल्प', 'न्यून', 'तनि', 'तनिक', 'कुछ', 'लेश', 'आंशिक', 'अनति', 'अप्रचुर', 'अबहु', 'ऊन', 'तोष', 'अभूयिष्ट', 'अभूरि', 'समाधानित', 'निपटा_हुआ', 'सुलझा_हुआ', 'सुलझा', 'वर्षा_कालीन', 'बरसाती', 'बारानी', 'निर्जल', 'निर्जला', 'पहिएदार', 'पहियेदार', 'नंगे_पैर']\n",
            "['लड़ना', 'मारना', 'लूटना', 'पीटना', 'कूटना', 'भेदभाव', 'फोड़ना', 'तोड़ना', 'उखाड़ना', 'लड़ना', 'मारना', 'उखाड़ना']\n",
            "['बीजेपी ', 'मोदी ', 'माओवादियों ', 'इस्लाम ', 'धमकी ', 'सुरक्षा ', 'धर्म ', 'साले ', 'कुत्ते ', 'कुतिया', 'कुते ', 'कुत्ती', 'कुत्तो', 'कमीना', 'कमीनी', 'साला', 'साली', 'हरामी', 'हरामखोर', 'बहनचोद', 'मादरचोद', 'चूतिया', 'चूत', 'चुत', 'टट्टी', 'नाजायज', 'झांट', 'सुअर', 'बेटीचोद', 'गांड', 'भोसड़ी', 'रन्डी', 'रांड', 'भड़वे', 'लौड़ा', 'लोडे', 'लवड़ा', 'चोर ', 'औलाद ', 'चीन ', 'औकात ', 'चुनौती', 'कश्मीर ', 'ज़ुल्म ', 'मरकज ', 'भारत', 'आतंकवाद', 'इस्लामिक', 'तालिबानी', 'हिन्दू ', 'अर्नब ', 'गद्दारों ', 'कलंकित ', 'तोड़फोड़ ', 'शिवसेना ', 'मंदिर ', 'राम ', 'हिन्दुओं ', 'शूद्र ', 'मुसलमान ', 'विपक्षी ', 'आग ', 'कॉंग्रेस ', 'आतंकवादी ', 'डायन ', 'पलटू ', 'फेंकूँ ', 'पाकिस्तान ', 'जिंदाबाद ', 'आतंकी ', 'आतंकी ', 'आतंकियों ', 'हिंदुस्तान ', 'हिन्दुओं', 'नेता', 'गुलाम ', 'पीओके ', 'आरएसएस ', 'भैंसियो ', 'चमचों ', 'पिल्ला ', 'गधे ', 'तबाह ', 'मुसलमान ', 'मुसलमानों ', 'मौलवी ', 'धर्म ']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KWR9UfCpYFIb"
      },
      "source": [
        "## Calculating Scores without Subjective Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lEYAJ25UZBgo"
      },
      "source": [
        "### Only Semantic feature set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQIDn-pKNn4V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6212281d-7fea-4f3d-8e89-1afb3c246648"
      },
      "source": [
        "for row in rows:                                                      # Iterate over all rows\n",
        "    strongcount = 0                                                   # Initialize strong count\n",
        "    hlexcount = 0                                                     # Initialize hlex count\n",
        "    weakcount = 0                                                     # Initialize weak count\n",
        "    themecount = 0                                                    # Initialize theme count                  \n",
        "    if any([word in row[1] for word in strongly_negative_words]):     # If any of the strongly negative words are in the tweet\n",
        "      strongcount += 1                                                # Increment strong count\n",
        "    # if any([word in row[1] for word in hlex]):                        # If any of the hlex words are in the tweet\n",
        "    #   hlexcount += 1                                                  # Increment hlex count\n",
        "    if any([word in row[1] for word in weakly_negative_words]):       # If any of the weakly negative words are in the tweet\n",
        "      weakcount += 1                                                  # Increment weak count    \n",
        "    # if any([word in row[1] for word in themenouns]):                  # If any of the theme nouns are in the tweet\n",
        "    #   themecount += 1                                                 # Increment theme count\n",
        "\n",
        "    if strongcount >= 2:                                              # If strong count is greater than or equal to 2\n",
        "        row.append(\"strongly hateful\")                               # Append strongly hateful to the row \n",
        "    elif strongcount == 1:                                            # Else if strong count is 1\n",
        "      if hlexcount >= 1 or themecount >= 1:                           # If hlex count is 1 or theme count is 1\n",
        "        row.append(\"strongly hateful\")                                # Append strongly hateful to the row\n",
        "      else:                                                           # Else\n",
        "        row.append(\"weakly hateful\")                                  # Append weakly hateful to the row \n",
        "    elif strongcount == 0:                                            # Else if strong count is 0\n",
        "      if themecount >= 1 and hlexcount >= 1:                          # If theme count is 1 and hlex count is 1\n",
        "        row.append(\"strongly hateful\")                                # Append strongly hateful to the row\n",
        "      elif themecount >=1 and weakcount >= 1:                         # Else if theme count is 1 and weak count is 1\n",
        "        row.append(\"weakly hateful\")                                  # Append weakly hateful to the row\n",
        "      elif hlexcount == 1:                                            # Else if hlex count is 1\n",
        "        row.append(\"weakly hateful\")                                  # Append weakly hateful to the row\n",
        "      else:                                                           # Else\n",
        "        row.append(\"No Hate\")                                         # Append No Hate to the row\n",
        "\n",
        "\n",
        "# total rows = toal number of rows\n",
        "total_rows = [row for row in rows]\n",
        "\n",
        "# no_hate_rows = number of rows that are marked to have no hate\n",
        "no_hate_rows = [row for row in rows if row[4] == \"No Hate\"]\n",
        "# correct_no_hate_rows = number of rows that have no hate speech and are correctly marked\n",
        "correct_no_hate_rows = [row for row in no_hate_rows if row[4] == \"No Hate\" and row[2] == \"non-hostile\"]\n",
        "# weak_hate_rows = number of rows that are marked to have weak hate\n",
        "weak_hate_rows = [row for row in rows if row[4] == \"weakly hateful\"]\n",
        "# correct_weak_hate_rows = number of rows that have weak hate speech and are correctly marked\n",
        "correct_weak_hate_rows = [row for row in weak_hate_rows if row[4] == \"weakly hateful\" and (row[2] == \"fake\" or row[2] == \"defamation\")]\n",
        "# strong_hate_rows = number of rows that are marked to have strong hate\n",
        "strong_hate_rows = [row for row in rows if row[4] == \"strongly hateful\"]\n",
        "# correct_strong_hate_rows = number of rows that have strong hate speech and are correctly marked\n",
        "correct_strong_hate_rows = [row for row in strong_hate_rows if row[4] == \"strongly hateful\" and row[2] != \"non-hostile\" and row[2] != \"fake\" and row[2] != \"defamation\"]\n",
        "# false negatives in the no hate list\n",
        "false_neg_no_hate = [row for row in no_hate_rows if row[2] == \"non-hostile\" and row[4] != \"No Hate\"]\n",
        "# false negatives in the weak hate list\n",
        "false_neg_weak_hate = [row for row in weak_hate_rows if row[2] == \"fake\" or row[2] == \"defamation\" and row[4] != \"weakly hateful\"]\n",
        "# false negatives in the strong hate list\n",
        "false_neg_strong_hate = [row for row in strong_hate_rows if row[2] != \"non-hostile\" and row[2] != \"fake\" and row[2] != \"defamation\" and row[4] != \"strongly hateful\"]\n",
        "\n",
        "# calculating precision\n",
        "precision = (len(correct_no_hate_rows)+len(correct_strong_hate_rows)+len(correct_weak_hate_rows))/(len(no_hate_rows)+len(strong_hate_rows)+len(weak_hate_rows))\n",
        "# calculating recall\n",
        "recall = (len(correct_no_hate_rows)+len(correct_strong_hate_rows)+len(correct_weak_hate_rows))/(len(correct_no_hate_rows)+len(correct_strong_hate_rows)+len(correct_weak_hate_rows)+len(false_neg_no_hate)+len(false_neg_strong_hate)+len(false_neg_weak_hate))\n",
        "# calculating F1 score\n",
        "f1 = 2*precision*recall/(precision+recall)\n",
        "\n",
        "print(\"Total no. of rows: {}\".format(len(total_rows)))                  # total no. of rows\n",
        "print(\"No Hate: {}\".format(len(no_hate_rows)))                          # no hate rows\n",
        "print(\"Actual no hate: {}\".format(len(correct_no_hate_rows)))           # actual no hate rows\n",
        "print(\"Weak Hate: {}\".format(len(weak_hate_rows)))                      # weak hate rows      \n",
        "print(\"Actual weak hate: {}\".format(len(correct_weak_hate_rows)))       # actual weak hate rows\n",
        "print(\"Strong Hate: {}\".format(len(strong_hate_rows)))                  # strong hate rows\n",
        "print(\"Actual strong hate: {}\".format(len(correct_strong_hate_rows)))   # actual strong hate rows\n",
        "# print precision\n",
        "print(\"Precision: {}\".format(precision))\n",
        "# print recall\n",
        "print(\"Recall: {}\".format(recall))\n",
        "# print f1\n",
        "print(\"F-score: {}\".format(f1))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total no. of rows: 811\n",
            "No Hate: 357\n",
            "Actual no hate: 207\n",
            "Weak Hate: 454\n",
            "Actual weak hate: 112\n",
            "Strong Hate: 0\n",
            "Actual strong hate: 0\n",
            "Precision: 0.3933415536374846\n",
            "Recall: 0.7799511002444988\n",
            "F-score: 0.5229508196721312\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hqy7pvksZLyT"
      },
      "source": [
        "### Semantic + Hate Lexicon"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmOcHTyUmB4P",
        "outputId": "c5a55ff2-1194-4f71-b505-ed557f8da634"
      },
      "source": [
        "for row in rows:                                                      # Iterate over all rows\n",
        "    strongcount = 0                                                   # Initialize strong count\n",
        "    hlexcount = 0                                                     # Initialize hlex count\n",
        "    weakcount = 0                                                     # Initialize weak count\n",
        "    themecount = 0                                                    # Initialize theme count                  \n",
        "    if any([word in row[1] for word in strongly_negative_words]):     # If any of the strongly negative words are in the tweet\n",
        "      strongcount += 1                                                # Increment strong count\n",
        "    if any([word in row[1] for word in hlex]):                        # If any of the hlex words are in the tweet\n",
        "      hlexcount += 1                                                  # Increment hlex count\n",
        "    if any([word in row[1] for word in weakly_negative_words]):       # If any of the weakly negative words are in the tweet\n",
        "      weakcount += 1                                                  # Increment weak count    \n",
        "    # if any([word in row[1] for word in themenouns]):                  # If any of the theme nouns are in the tweet\n",
        "    #   themecount += 1                                                 # Increment theme count\n",
        "\n",
        "    if strongcount >= 2:                                              # If strong count is greater than or equal to 2\n",
        "        row[4] = \"strongly hateful\"                                # Append strongly hateful to the row \n",
        "    elif strongcount == 1:                                            # Else if strong count is 1\n",
        "      if hlexcount >= 1 or themecount >= 1:                           # If hlex count is 1 or theme count is 1\n",
        "        row[4] = \"strongly hateful\"                                # Append strongly hateful to the row\n",
        "      else:                                                           # Else\n",
        "        row[4] = \"weakly hateful\"                                  # Append weakly hateful to the row \n",
        "    elif strongcount == 0:                                            # Else if strong count is 0\n",
        "      if themecount >= 1 and hlexcount >= 1:                          # If theme count is 1 and hlex count is 1\n",
        "        row[4] = \"strongly hateful\"                                # Append strongly hateful to the row\n",
        "      elif themecount >=1 and weakcount >= 1:                         # Else if theme count is 1 and weak count is 1\n",
        "        row[4] = \"weakly hateful\"                                  # Append weakly hateful to the row\n",
        "      elif hlexcount == 1:                                            # Else if hlex count is 1\n",
        "        row[4] = \"weakly hateful\"                                  # Append weakly hateful to the row\n",
        "      else:                                                           # Else\n",
        "        row[4] = \"No Hate\"                                        # Append No Hate to the row\n",
        "\n",
        "\n",
        "# total rows = toal number of rows\n",
        "total_rows = [row for row in rows]\n",
        "\n",
        "# no_hate_rows = number of rows that are marked to have no hate\n",
        "no_hate_rows = [row for row in rows if row[4] == \"No Hate\"]\n",
        "# correct_no_hate_rows = number of rows that have no hate speech and are correctly marked\n",
        "correct_no_hate_rows = [row for row in no_hate_rows if row[4] == \"No Hate\" and row[2] == \"non-hostile\"]\n",
        "# weak_hate_rows = number of rows that are marked to have weak hate\n",
        "weak_hate_rows = [row for row in rows if row[4] == \"weakly hateful\"]\n",
        "# correct_weak_hate_rows = number of rows that have weak hate speech and are correctly marked\n",
        "correct_weak_hate_rows = [row for row in weak_hate_rows if row[4] == \"weakly hateful\" and (row[2] == \"fake\" or row[2] == \"defamation\")]\n",
        "# strong_hate_rows = number of rows that are marked to have strong hate\n",
        "strong_hate_rows = [row for row in rows if row[4] == \"strongly hateful\"]\n",
        "# correct_strong_hate_rows = number of rows that have strong hate speech and are correctly marked\n",
        "correct_strong_hate_rows = [row for row in strong_hate_rows if row[4] == \"strongly hateful\" and row[2] != \"non-hostile\" and row[2] != \"fake\" and row[2] != \"defamation\"]\n",
        "# false negatives in the no hate list\n",
        "false_neg_no_hate = [row for row in no_hate_rows if row[2] == \"non-hostile\" and row[4] != \"No Hate\"]\n",
        "# false negatives in the weak hate list\n",
        "false_neg_weak_hate = [row for row in weak_hate_rows if row[2] == \"fake\" or row[2] == \"defamation\" and row[4] != \"weakly hateful\"]\n",
        "# false negatives in the strong hate list\n",
        "false_neg_strong_hate = [row for row in strong_hate_rows if row[2] != \"non-hostile\" and row[2] != \"fake\" and row[2] != \"defamation\" and row[4] != \"strongly hateful\"]\n",
        "\n",
        "# calculating precision\n",
        "precision = (len(correct_no_hate_rows)+len(correct_strong_hate_rows)+len(correct_weak_hate_rows))/(len(no_hate_rows)+len(strong_hate_rows)+len(weak_hate_rows))\n",
        "# calculating recall\n",
        "recall = (len(correct_no_hate_rows)+len(correct_strong_hate_rows)+len(correct_weak_hate_rows))/(len(correct_no_hate_rows)+len(correct_strong_hate_rows)+len(correct_weak_hate_rows)+len(false_neg_no_hate)+len(false_neg_strong_hate)+len(false_neg_weak_hate))\n",
        "# calculating F1 score\n",
        "f1 = 2*precision*recall/(precision+recall)\n",
        "\n",
        "print(\"Total no. of rows: {}\".format(len(total_rows)))                  # total no. of rows\n",
        "print(\"No Hate: {}\".format(len(no_hate_rows)))                          # no hate rows\n",
        "print(\"Actual no hate: {}\".format(len(correct_no_hate_rows)))           # actual no hate rows\n",
        "print(\"Weak Hate: {}\".format(len(weak_hate_rows)))                      # weak hate rows      \n",
        "print(\"Actual weak hate: {}\".format(len(correct_weak_hate_rows)))       # actual weak hate rows\n",
        "print(\"Strong Hate: {}\".format(len(strong_hate_rows)))                  # strong hate rows\n",
        "print(\"Actual strong hate: {}\".format(len(correct_strong_hate_rows)))   # actual strong hate rows\n",
        "# print precision\n",
        "print(\"Precision: {}\".format(precision))\n",
        "# print recall\n",
        "print(\"Recall: {}\".format(recall))\n",
        "# print f1\n",
        "print(\"F-score: {}\".format(f1))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total no. of rows: 811\n",
            "No Hate: 355\n",
            "Actual no hate: 206\n",
            "Weak Hate: 455\n",
            "Actual weak hate: 112\n",
            "Strong Hate: 1\n",
            "Actual strong hate: 1\n",
            "Precision: 0.3933415536374846\n",
            "Recall: 0.7799511002444988\n",
            "F-score: 0.5229508196721312\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HbEg764EZSlI"
      },
      "source": [
        "### Semantic + Hate Lexicon + Thematic Nouns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vG1O1mUVmCL8",
        "outputId": "c4c29c0f-daa6-4ff7-fbb7-eaa8aa577bc1"
      },
      "source": [
        "for row in rows:                                                      # Iterate over all rows\n",
        "    strongcount = 0                                                   # Initialize strong count\n",
        "    hlexcount = 0                                                     # Initialize hlex count\n",
        "    weakcount = 0                                                     # Initialize weak count\n",
        "    themecount = 0                                                    # Initialize theme count                  \n",
        "    if any([word in row[1] for word in strongly_negative_words]):     # If any of the strongly negative words are in the tweet\n",
        "      strongcount += 1                                                # Increment strong count\n",
        "    if any([word in row[1] for word in hlex]):                        # If any of the hlex words are in the tweet\n",
        "      hlexcount += 1                                                  # Increment hlex count\n",
        "    if any([word in row[1] for word in weakly_negative_words]):       # If any of the weakly negative words are in the tweet\n",
        "      weakcount += 1                                                  # Increment weak count    \n",
        "    if any([word in row[1] for word in themenouns]):                  # If any of the theme nouns are in the tweet\n",
        "      themecount += 1                                                 # Increment theme count\n",
        "\n",
        "    if strongcount >= 2:                                              # If strong count is greater than or equal to 2\n",
        "        row[4] = \"strongly hateful\"                                # Append strongly hateful to the row \n",
        "    elif strongcount == 1:                                            # Else if strong count is 1\n",
        "      if hlexcount >= 1 or themecount >= 1:                           # If hlex count is 1 or theme count is 1\n",
        "        row[4] = \"strongly hateful\"                                # Append strongly hateful to the row\n",
        "      else:                                                           # Else\n",
        "        row[4] = \"weakly hateful\"                                  # Append weakly hateful to the row \n",
        "    elif strongcount == 0:                                            # Else if strong count is 0\n",
        "      if themecount >= 1 and hlexcount >= 1:                          # If theme count is 1 and hlex count is 1\n",
        "        row[4] = \"strongly hateful\"                                # Append strongly hateful to the row\n",
        "      elif themecount >=1 and weakcount >= 1:                         # Else if theme count is 1 and weak count is 1\n",
        "        row[4] = \"weakly hateful\"                                  # Append weakly hateful to the row\n",
        "      elif hlexcount == 1:                                            # Else if hlex count is 1\n",
        "        row[4] = \"weakly hateful\"                                 # Append weakly hateful to the row\n",
        "      else:                                                           # Else\n",
        "        row[4] = \"No Hate\"                                        # Append No Hate to the row\n",
        "\n",
        "\n",
        "# total rows = toal number of rows\n",
        "total_rows = [row for row in rows]\n",
        "\n",
        "# no_hate_rows = number of rows that are marked to have no hate\n",
        "no_hate_rows = [row for row in rows if row[4] == \"No Hate\"]\n",
        "# correct_no_hate_rows = number of rows that have no hate speech and are correctly marked\n",
        "correct_no_hate_rows = [row for row in no_hate_rows if row[4] == \"No Hate\" and row[2] == \"non-hostile\"]\n",
        "# weak_hate_rows = number of rows that are marked to have weak hate\n",
        "weak_hate_rows = [row for row in rows if row[4] == \"weakly hateful\"]\n",
        "# correct_weak_hate_rows = number of rows that have weak hate speech and are correctly marked\n",
        "correct_weak_hate_rows = [row for row in weak_hate_rows if row[4] == \"weakly hateful\" and (row[2] == \"fake\" or row[2] == \"defamation\")]\n",
        "# strong_hate_rows = number of rows that are marked to have strong hate\n",
        "strong_hate_rows = [row for row in rows if row[4] == \"strongly hateful\"]\n",
        "# correct_strong_hate_rows = number of rows that have strong hate speech and are correctly marked\n",
        "correct_strong_hate_rows = [row for row in strong_hate_rows if row[4] == \"strongly hateful\" and row[2] != \"non-hostile\" and row[2] != \"fake\" and row[2] != \"defamation\"]\n",
        "# false negatives in the no hate list\n",
        "false_neg_no_hate = [row for row in no_hate_rows if row[2] == \"non-hostile\" and row[4] != \"No Hate\"]\n",
        "# false negatives in the weak hate list\n",
        "false_neg_weak_hate = [row for row in weak_hate_rows if row[2] == \"fake\" or row[2] == \"defamation\" and row[4] != \"weakly hateful\"]\n",
        "# false negatives in the strong hate list\n",
        "false_neg_strong_hate = [row for row in strong_hate_rows if row[2] != \"non-hostile\" and row[2] != \"fake\" and row[2] != \"defamation\" and row[4] != \"strongly hateful\"]\n",
        "\n",
        "# calculating precision\n",
        "precision = (len(correct_no_hate_rows)+len(correct_strong_hate_rows)+len(correct_weak_hate_rows))/(len(no_hate_rows)+len(strong_hate_rows)+len(weak_hate_rows))\n",
        "# calculating recall\n",
        "recall = (len(correct_no_hate_rows)+len(correct_strong_hate_rows)+len(correct_weak_hate_rows))/(len(correct_no_hate_rows)+len(correct_strong_hate_rows)+len(correct_weak_hate_rows)+len(false_neg_no_hate)+len(false_neg_strong_hate)+len(false_neg_weak_hate))\n",
        "# calculating F1 score\n",
        "f1 = 2*precision*recall/(precision+recall)\n",
        "\n",
        "print(\"Total no. of rows: {}\".format(len(total_rows)))                  # total no. of rows\n",
        "print(\"No Hate: {}\".format(len(no_hate_rows)))                          # no hate rows\n",
        "print(\"Actual no hate: {}\".format(len(correct_no_hate_rows)))           # actual no hate rows\n",
        "print(\"Weak Hate: {}\".format(len(weak_hate_rows)))                      # weak hate rows      \n",
        "print(\"Actual weak hate: {}\".format(len(correct_weak_hate_rows)))       # actual weak hate rows\n",
        "print(\"Strong Hate: {}\".format(len(strong_hate_rows)))                  # strong hate rows\n",
        "print(\"Actual strong hate: {}\".format(len(correct_strong_hate_rows)))   # actual strong hate rows\n",
        "# print precision\n",
        "print(\"Precision: {}\".format(precision))\n",
        "# print recall\n",
        "print(\"Recall: {}\".format(recall))\n",
        "# print f1\n",
        "print(\"F-score: {}\".format(f1))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total no. of rows: 811\n",
            "No Hate: 293\n",
            "Actual no hate: 185\n",
            "Weak Hate: 344\n",
            "Actual weak hate: 85\n",
            "Strong Hate: 174\n",
            "Actual strong hate: 75\n",
            "Precision: 0.4254007398273736\n",
            "Recall: 0.843520782396088\n",
            "F-score: 0.5655737704918032\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-lWHjD3FYOoQ"
      },
      "source": [
        "## Calculating Scores with Subjective Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erIbFiW6BR-7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a8cf0cd-6c5d-4d1a-bbce-11e876efd7a6"
      },
      "source": [
        "counter = 0                             # Counter for the number of tweets\n",
        "subj_rows = []                          # List of all the subjective tweets\n",
        "for row in rows:                        # Iterate through each row\n",
        "  if row[3] <= -0.5 or row[3] >= 1:     # subjective sentence condition\n",
        "    subj_rows.append(row)               # Append the row to the list\n",
        "    counter += 1\n",
        "\n",
        "print(\"Number of Subjective Sentences: \")\n",
        "print(counter)                          # Print the number of subjective tweets"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of Subjective Sentences: \n",
            "355\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-g57Y2EZa-o"
      },
      "source": [
        "### Semantic feature set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9HwRDrzLOwJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f90a1305-9602-4ac0-a3a7-65c2ac9e4770"
      },
      "source": [
        "for row in rows:                                                    # Iterate over all rows\n",
        "  if row[3] <= -0.5 or row[3] >= 1:                                 # If the score is over -0.5 or 0.5\n",
        "    strongcount = 0                                                 # Set strongcount to 0\n",
        "    hlexcount = 0                                                   # Set hlexcount to 0\n",
        "    weakcount = 0                                                   # Set weakcount to 0                   \n",
        "    themecount = 0                                                  # Set themecount to 0\n",
        "    if any([word in row[1] for word in strongly_negative_words]):   # If any of the strongly negative words are in the tweet\n",
        "      strongcount += 1                                              # Add 1 to strongcount  \n",
        "    # if any([word in row[1] for word in hlex]):                      # If any of the hlex words are in the tweet\n",
        "    #   hlexcount += 1                                                # Add 1 to hlexcount\n",
        "    if any([word in row[1] for word in weakly_negative_words]):     # If any of the weakly negative words are in the tweet\n",
        "      weakcount += 1                                                # Add 1 to weakcount                  \n",
        "    # if any([word in row[1] for word in themenouns]):                # If any of the themenouns words are in the tweet\n",
        "    #   themecount += 1                                               # Add 1 to themecount\n",
        "\n",
        "    if strongcount >= 2:                                            # If strongcount is greater than or equal to 2\n",
        "        row.append(\"strongly hateful\")                              # Append strongly hate to the row\n",
        "    elif strongcount == 1:                                          # Else if strongcount is equal to 1\n",
        "      if hlexcount >= 1 or themecount >= 1:                         # If hlexcount is greater than or equal to 1 or themecount is greater than or equal to 1\n",
        "        row.append(\"strongly hateful\")                              # Append strongly hate to the row               \n",
        "      else:                                                         # Else  \n",
        "        row.append(\"weakly hateful\")                                # Append weakly hate to the row\n",
        "    elif strongcount == 0:                                          # Else if strongcount is equal to 0\n",
        "      if themecount >= 1 and hlexcount >= 1:                        # If themecount is greater than or equal to 1 and hlexcount is greater than or equal to 1\n",
        "        row.append(\"strongly hateful\")                              # Append strongly hate to the row \n",
        "      elif themecount >=1 and weakcount >= 1:                       # Else if themecount is greater than or equal to 1 and weakcount is greater than or equal to 1\n",
        "        row.append(\"weakly hateful\")                                # Append weakly hate to the row\n",
        "      elif hlexcount == 1:                                          # Else if hlexcount is equal to 1\n",
        "        row.append(\"weakly hateful\")                                # Append weakly hate to the row\n",
        "      else:                                                         # Else                    \n",
        "        row.append(\"No Hate\")                                       # Append No Hate to the row\n",
        "  else:                                                             # Else\n",
        "     row.append(\"No Hate\")                                          # Append No Hate to the row\n",
        "\n",
        "\n",
        "total_rows = [row for row in rows]\n",
        "\n",
        "no_hate_rows = [row for row in rows if row[5] == \"No Hate\"]\n",
        "correct_no_hate_rows = [row for row in no_hate_rows if row[5] == \"No Hate\" and row[2] == \"non-hostile\"]\n",
        "weak_hate_rows = [row for row in rows if row[5] == \"weakly hateful\"]\n",
        "correct_weak_hate_rows = [row for row in weak_hate_rows if row[5] == \"weakly hateful\" and (row[2] == \"fake\" or row[2] == \"defamation\")]\n",
        "strong_hate_rows = [row for row in rows if row[5] == \"strongly hateful\"]\n",
        "correct_strong_hate_rows = [row for row in strong_hate_rows if row[5] == \"strongly hateful\" and row[2] != \"non-hostile\" and row[2] != \"fake\" and row[2] != \"defamation\"]\n",
        "\n",
        "false_neg_no_hate = [row for row in no_hate_rows if row[2] == \"non-hostile\" and row[5] != \"No Hate\"]\n",
        "false_neg_weak_hate = [row for row in weak_hate_rows if row[2] == \"fake\" or row[2] == \"defamation\" and row[5] != \"weakly hateful\"]\n",
        "false_neg_strong_hate = [row for row in strong_hate_rows if row[2] != \"non-hostile\" and row[2] != \"fake\" and row[2] != \"defamation\" and row[5] != \"strongly hateful\"]\n",
        "\n",
        "precision = (len(correct_no_hate_rows)+len(correct_strong_hate_rows)+len(correct_weak_hate_rows))/(len(no_hate_rows)+len(strong_hate_rows)+len(weak_hate_rows))\n",
        "recall = (len(correct_no_hate_rows)+len(correct_strong_hate_rows)+len(correct_weak_hate_rows))/(len(correct_no_hate_rows)+len(correct_strong_hate_rows)+len(correct_weak_hate_rows)+len(false_neg_no_hate)+len(false_neg_strong_hate)+len(false_neg_weak_hate))\n",
        "f1 = 2*precision*recall/(precision+recall)\n",
        "\n",
        "print(\"Total no. of rows: {}\".format(len(total_rows)))\n",
        "print(\"No Hate: {}\".format(len(no_hate_rows)))\n",
        "print(\"Actual no hate: {}\".format(len(correct_no_hate_rows)))\n",
        "print(\"Weak Hate: {}\".format(len(weak_hate_rows)))\n",
        "print(\"Actual weak hate: {}\".format(len(correct_weak_hate_rows)))\n",
        "print(\"Strong Hate: {}\".format(len(strong_hate_rows)))\n",
        "print(\"Actual strong hate: {}\".format(len(correct_strong_hate_rows)))\n",
        "print(\"Precision: {}\".format(precision))\n",
        "print(\"Recall: {}\".format(recall))\n",
        "print(\"F-score: {}\".format(f1))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total no. of rows: 811\n",
            "No Hate: 479\n",
            "Actual no hate: 282\n",
            "Weak Hate: 332\n",
            "Actual weak hate: 86\n",
            "Strong Hate: 0\n",
            "Actual strong hate: 0\n",
            "Precision: 0.45376078914919854\n",
            "Recall: 0.8498845265588915\n",
            "F-score: 0.5916398713826366\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXxMHvFpZdaF"
      },
      "source": [
        "### Semantic + Hate Lexicon "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8wBRGSWQrL2r",
        "outputId": "c455637c-c486-4a6a-c8e9-52e9cb684c33"
      },
      "source": [
        "for row in rows:                                                    # Iterate over all rows\n",
        "  if row[3] <= -0.5 or row[3] >= 1:                                 # If the score is over -0.5 or 0.5\n",
        "    strongcount = 0                                                 # Set strongcount to 0\n",
        "    hlexcount = 0                                                   # Set hlexcount to 0\n",
        "    weakcount = 0                                                   # Set weakcount to 0                   \n",
        "    themecount = 0                                                  # Set themecount to 0\n",
        "    if any([word in row[1] for word in strongly_negative_words]):   # If any of the strongly negative words are in the tweet\n",
        "      strongcount += 1                                              # Add 1 to strongcount  \n",
        "    if any([word in row[1] for word in hlex]):                      # If any of the hlex words are in the tweet\n",
        "      hlexcount += 1                                                # Add 1 to hlexcount\n",
        "    if any([word in row[1] for word in weakly_negative_words]):     # If any of the weakly negative words are in the tweet\n",
        "      weakcount += 1                                                # Add 1 to weakcount                  \n",
        "    # if any([word in row[1] for word in themenouns]):                # If any of the themenouns words are in the tweet\n",
        "    #   themecount += 1                                               # Add 1 to themecount\n",
        "\n",
        "    if strongcount >= 2:                                              # If strong count is greater than or equal to 2\n",
        "        row[5] = \"strongly hateful\"                                # Append strongly hateful to the row \n",
        "    elif strongcount == 1:                                            # Else if strong count is 1\n",
        "      if hlexcount >= 1 or themecount >= 1:                           # If hlex count is 1 or theme count is 1\n",
        "        row[5] = \"strongly hateful\"                                # Append strongly hateful to the row\n",
        "      else:                                                           # Else\n",
        "        row[5] = \"weakly hateful\"                                  # Append weakly hateful to the row \n",
        "    elif strongcount == 0:                                            # Else if strong count is 0\n",
        "      if themecount >= 1 and hlexcount >= 1:                          # If theme count is 1 and hlex count is 1\n",
        "        row[5] = \"strongly hateful\"                                # Append strongly hateful to the row\n",
        "      elif themecount >=1 and weakcount >= 1:                         # Else if theme count is 1 and weak count is 1\n",
        "        row[5] = \"weakly hateful\"                                  # Append weakly hateful to the row\n",
        "      elif hlexcount == 1:                                            # Else if hlex count is 1\n",
        "        row[5] = \"weakly hateful\"                                 # Append weakly hateful to the row\n",
        "      else:                                                           # Else\n",
        "        row[5] = \"No Hate\"                                        # Append No Hate to the row\n",
        "\n",
        "\n",
        "total_rows = [row for row in rows]\n",
        "\n",
        "no_hate_rows = [row for row in rows if row[5] == \"No Hate\"]\n",
        "correct_no_hate_rows = [row for row in no_hate_rows if row[5] == \"No Hate\" and row[2] == \"non-hostile\"]\n",
        "weak_hate_rows = [row for row in rows if row[5] == \"weakly hateful\"]\n",
        "correct_weak_hate_rows = [row for row in weak_hate_rows if row[5] == \"weakly hateful\" and (row[2] == \"fake\" or row[2] == \"defamation\")]\n",
        "strong_hate_rows = [row for row in rows if row[5] == \"strongly hateful\"]\n",
        "correct_strong_hate_rows = [row for row in strong_hate_rows if row[5] == \"strongly hateful\" and row[2] != \"non-hostile\" and row[2] != \"fake\" and row[2] != \"defamation\"]\n",
        "\n",
        "false_neg_no_hate = [row for row in no_hate_rows if row[2] == \"non-hostile\" and row[5] != \"No Hate\"]\n",
        "false_neg_weak_hate = [row for row in weak_hate_rows if row[2] == \"fake\" or row[2] == \"defamation\" and row[5] != \"weakly hateful\"]\n",
        "false_neg_strong_hate = [row for row in strong_hate_rows if row[2] != \"non-hostile\" and row[2] != \"fake\" and row[2] != \"defamation\" and row[5] != \"strongly hateful\"]\n",
        "\n",
        "precision = (len(correct_no_hate_rows)+len(correct_strong_hate_rows)+len(correct_weak_hate_rows))/(len(no_hate_rows)+len(strong_hate_rows)+len(weak_hate_rows))\n",
        "recall = (len(correct_no_hate_rows)+len(correct_strong_hate_rows)+len(correct_weak_hate_rows))/(len(correct_no_hate_rows)+len(correct_strong_hate_rows)+len(correct_weak_hate_rows)+len(false_neg_no_hate)+len(false_neg_strong_hate)+len(false_neg_weak_hate))\n",
        "f1 = 2*precision*recall/(precision+recall)\n",
        "\n",
        "print(\"Total no. of rows: {}\".format(len(total_rows)))\n",
        "print(\"No Hate: {}\".format(len(no_hate_rows)))\n",
        "print(\"Actual no hate: {}\".format(len(correct_no_hate_rows)))\n",
        "print(\"Weak Hate: {}\".format(len(weak_hate_rows)))\n",
        "print(\"Actual weak hate: {}\".format(len(correct_weak_hate_rows)))\n",
        "print(\"Strong Hate: {}\".format(len(strong_hate_rows)))\n",
        "print(\"Actual strong hate: {}\".format(len(correct_strong_hate_rows)))\n",
        "print(\"Precision: {}\".format(precision))\n",
        "print(\"Recall: {}\".format(recall))\n",
        "print(\"F-score: {}\".format(f1))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total no. of rows: 811\n",
            "No Hate: 479\n",
            "Actual no hate: 282\n",
            "Weak Hate: 331\n",
            "Actual weak hate: 86\n",
            "Strong Hate: 1\n",
            "Actual strong hate: 1\n",
            "Precision: 0.45499383477188654\n",
            "Recall: 0.8502304147465438\n",
            "F-score: 0.5927710843373494\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBg1o7MSZeox"
      },
      "source": [
        "### Semantic + Hate Lexicon + Thematic Nouns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5WzWpPKWrN21",
        "outputId": "0a2c4bc0-18e7-4f87-f814-4b49443a5a1d"
      },
      "source": [
        "for row in rows:                                                    # Iterate over all rows\n",
        "  if row[3] <= -0.5 or row[3] >= 1:                                 # If the score is over -0.5 or 0.5\n",
        "    strongcount = 0                                                 # Set strongcount to 0\n",
        "    hlexcount = 0                                                   # Set hlexcount to 0\n",
        "    weakcount = 0                                                   # Set weakcount to 0                   \n",
        "    themecount = 0                                                  # Set themecount to 0\n",
        "    if any([word in row[1] for word in strongly_negative_words]):   # If any of the strongly negative words are in the tweet\n",
        "      strongcount += 1                                              # Add 1 to strongcount  \n",
        "    if any([word in row[1] for word in hlex]):                      # If any of the hlex words are in the tweet\n",
        "      hlexcount += 1                                                # Add 1 to hlexcount\n",
        "    if any([word in row[1] for word in weakly_negative_words]):     # If any of the weakly negative words are in the tweet\n",
        "      weakcount += 1                                                # Add 1 to weakcount                  \n",
        "    if any([word in row[1] for word in themenouns]):                # If any of the themenouns words are in the tweet\n",
        "      themecount += 1                                               # Add 1 to themecount\n",
        "\n",
        "    if strongcount >= 2:                                              # If strong count is greater than or equal to 2\n",
        "        row[5] = \"strongly hateful\"                                # Append strongly hateful to the row \n",
        "    elif strongcount == 1:                                            # Else if strong count is 1\n",
        "      if hlexcount >= 1 or themecount >= 1:                           # If hlex count is 1 or theme count is 1\n",
        "        row[5] = \"strongly hateful\"                                # Append strongly hateful to the row\n",
        "      else:                                                           # Else\n",
        "        row[5] = \"weakly hateful\"                                  # Append weakly hateful to the row \n",
        "    elif strongcount == 0:                                            # Else if strong count is 0\n",
        "      if themecount >= 1 and hlexcount >= 1:                          # If theme count is 1 and hlex count is 1\n",
        "        row[5] = \"strongly hateful\"                                # Append strongly hateful to the row\n",
        "      elif themecount >=1 and weakcount >= 1:                         # Else if theme count is 1 and weak count is 1\n",
        "        row[5] = \"weakly hateful\"                                  # Append weakly hateful to the row\n",
        "      elif hlexcount == 1:                                            # Else if hlex count is 1\n",
        "        row[5] = \"weakly hateful\"                                 # Append weakly hateful to the row\n",
        "      else:                                                           # Else\n",
        "        row[5] = \"No Hate\"                                        # Append No Hate to the row\n",
        "\n",
        "\n",
        "total_rows = [row for row in rows]\n",
        "\n",
        "no_hate_rows = [row for row in rows if row[5] == \"No Hate\"]\n",
        "correct_no_hate_rows = [row for row in no_hate_rows if row[5] == \"No Hate\" and row[2] == \"non-hostile\"]\n",
        "weak_hate_rows = [row for row in rows if row[5] == \"weakly hateful\"]\n",
        "correct_weak_hate_rows = [row for row in weak_hate_rows if row[5] == \"weakly hateful\" and (row[2] == \"fake\" or row[2] == \"defamation\")]\n",
        "strong_hate_rows = [row for row in rows if row[5] == \"strongly hateful\"]\n",
        "correct_strong_hate_rows = [row for row in strong_hate_rows if row[5] == \"strongly hateful\" and row[2] != \"non-hostile\" and row[2] != \"fake\" and row[2] != \"defamation\"]\n",
        "\n",
        "false_neg_no_hate = [row for row in no_hate_rows if row[2] == \"non-hostile\" and row[5] != \"No Hate\"]\n",
        "false_neg_weak_hate = [row for row in weak_hate_rows if row[2] == \"fake\" or row[2] == \"defamation\" and row[5] != \"weakly hateful\"]\n",
        "false_neg_strong_hate = [row for row in strong_hate_rows if row[2] != \"non-hostile\" and row[2] != \"fake\" and row[2] != \"defamation\" and row[5] != \"strongly hateful\"]\n",
        "\n",
        "precision = (len(correct_no_hate_rows)+len(correct_strong_hate_rows)+len(correct_weak_hate_rows))/(len(no_hate_rows)+len(strong_hate_rows)+len(weak_hate_rows))\n",
        "recall = (len(correct_no_hate_rows)+len(correct_strong_hate_rows)+len(correct_weak_hate_rows))/(len(correct_no_hate_rows)+len(correct_strong_hate_rows)+len(correct_weak_hate_rows)+len(false_neg_no_hate)+len(false_neg_strong_hate)+len(false_neg_weak_hate))\n",
        "f1 = 2*precision*recall/(precision+recall)\n",
        "\n",
        "print(\"Total no. of rows: {}\".format(len(total_rows)))\n",
        "print(\"No Hate: {}\".format(len(no_hate_rows)))\n",
        "print(\"Actual no hate: {}\".format(len(correct_no_hate_rows)))\n",
        "print(\"Weak Hate: {}\".format(len(weak_hate_rows)))\n",
        "print(\"Actual weak hate: {}\".format(len(correct_weak_hate_rows)))\n",
        "print(\"Strong Hate: {}\".format(len(strong_hate_rows)))\n",
        "print(\"Actual strong hate: {}\".format(len(correct_strong_hate_rows)))\n",
        "print(\"Precision: {}\".format(precision))\n",
        "print(\"Recall: {}\".format(recall))\n",
        "print(\"F-score: {}\".format(f1))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total no. of rows: 811\n",
            "No Hate: 473\n",
            "Actual no hate: 280\n",
            "Weak Hate: 208\n",
            "Actual weak hate: 51\n",
            "Strong Hate: 130\n",
            "Actual strong hate: 63\n",
            "Precision: 0.48581997533908755\n",
            "Recall: 0.9184149184149184\n",
            "F-score: 0.635483870967742\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzwZW-sZYxQF"
      },
      "source": [
        "## Exporting results into results.csv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVeHBwzkOL5N"
      },
      "source": [
        "import csv                                                                  # Importing the csv module\n",
        "\n",
        "fields = ['Unique ID', 'Post', 'Labels Set', 'Total Score', 'Hate Label' ,'Subjective Hate Label']   # Defining the fields of the csv file\n",
        "with open(\"results.csv\", 'w') as csvfile:                                   # Opening the file                          \n",
        "    # creating a csv writer object \n",
        "    csvwriter = csv.writer(csvfile) \n",
        "        \n",
        "    # writing the fields \n",
        "    csvwriter.writerow(fields) \n",
        "        \n",
        "    # writing the data rows \n",
        "    csvwriter.writerows(rows)"
      ],
      "execution_count": 30,
      "outputs": []
    }
  ]
}